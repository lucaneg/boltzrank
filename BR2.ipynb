{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# BoltzRank #\n",
    "## Luca Negrini - Mat. 956516 ##\n",
    "### From \"BoltzRank: Learning to Maximize Expected Ranking Gain\" ###\n",
    "#### Maxims M. Volkovs, Richard S. Zemel ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "#### Initialization ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext cython\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html\n",
    "from sklearn.datasets import load_svmlight_file \n",
    "\n",
    "# datasets available at: \n",
    "# https://www.microsoft.com/en-us/research/project/mslr/\n",
    "DATASET_FOLDER = \"C:/opt/kiis-training/MSLR-WEB10K/Fold1/\"\n",
    "PERM_FOLDER = DATASET_FOLDER + \"perms/\"\n",
    "METRIC_NAME = 'ndcg@10'#'BoltzRank-NDCG@10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Data loading ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureFile(path):\n",
    "    if not os.path.exists(path) or not os.path.isfile(path):\n",
    "        raise FileNotFoundError(\"'\" + path + \"': no such file\")        \n",
    "    return path\n",
    "\n",
    "def retrieveFileNames():\n",
    "    folder = DATASET_FOLDER + '/' if DATASET_FOLDER[-1:] != '/' else DATASET_FOLDER\n",
    "    train_file = ensureFile(folder + \"train.txt\")\n",
    "    valid_file = ensureFile(folder + \"vali.txt\")\n",
    "    test_file = ensureFile(folder + \"test.txt\")\n",
    "    return train_file, valid_file, test_file\n",
    "\n",
    "def loadDataset(path):\n",
    "    return load_svmlight_file(path, query_id=True)\n",
    "\n",
    "def loadLightGBM(svmlight_dataset):\n",
    "    query_lens = [sum(1 for _ in group) for key, group in itertools.groupby(svmlight_dataset[2])]\n",
    "    return lightgbm.Dataset(data=svmlight_dataset[0], label=svmlight_dataset[1], group=query_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, qid):\n",
    "        self.qid = qid\n",
    "        self.labels_to_docs = {}\n",
    "    def addlabel(self, label):\n",
    "        if not label in self.labels_to_docs:\n",
    "            self.labels_to_docs[label] = list()\n",
    "    def adddoc(self, label, doc):\n",
    "        self.labels_to_docs[label].append(doc)\n",
    "    def finalize(self, alllabels):\n",
    "        self.labels = np.zeros(len(self.labels_to_docs.keys()), dtype=int)\n",
    "        self.docs = np.empty(len(self.labels_to_docs.keys()), dtype=object)\n",
    "        i = 0\n",
    "        totaldocs = 0\n",
    "        sorteddict = sorted(self.labels_to_docs.items(), reverse = True)\n",
    "        for label, docs in sorteddict:\n",
    "            self.labels[i] = label\n",
    "            self.docs[i] = np.zeros(len(docs), dtype=int)\n",
    "            for j in range(len(docs)):\n",
    "                self.docs[i][j] = docs[j]\n",
    "            i += 1\n",
    "            totaldocs += len(docs)\n",
    "        self.alldocs = np.concatenate(self.docs)\n",
    "        self.flatlabels = np.zeros(totaldocs, dtype=np.double)\n",
    "        i = 0\n",
    "        for label, docs in sorteddict:\n",
    "            for j in range(len(docs)):\n",
    "                self.flatlabels[i] = label\n",
    "                i += 1       \n",
    "        k = min(10, len(self.alldocs))\n",
    "        self.idealdcg = dcg_k(self.alldocs, alllabels, k) \n",
    "        del self.labels_to_docs\n",
    "    def setperms(self, perms):\n",
    "        self.perms = perms\n",
    "    def setndcgs(self, ndcgs):\n",
    "        self.ndcgs = ndcgs\n",
    "    def __repr__(self):  \n",
    "        return str(self)\n",
    "    def __str__(self):\n",
    "        res = \"Query \" + str(self.qid) + \"[\"\n",
    "        res += \"\\nideal dcg: \" + str(self.idealdcg)\n",
    "        for i in range(len(self.labels)):\n",
    "            res += \"\\n\" + str(self.labels[i]) + \" -> \" + str(self.docs[i])\n",
    "        res += \"]\"\n",
    "        if hasattr(self, 'perms'):\n",
    "            for i in range(len(self.perms)):\n",
    "                res += \"\\n[\" + str(self.perms[i]) + \"] -> dcg: \" + str(self.ndcgs[i])\n",
    "        else:\n",
    "            res += \"\\nNo permutations computed yet\"\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "#  dataset: svmlight_dataset \n",
    "#      the datset to process\n",
    "# returned values:\n",
    "#  query_to_labels_to_documents: dict(int -> dict(float -> list(int)))\n",
    "#      a map containing, for each query in the dataset, the documents (row index in the dataset) provided \n",
    "#      in the input dataset grouped by label\n",
    "#  doc_to_query: dict(document -> query)\n",
    "#      a mapping between document (row index in the dataset) and the relative query\n",
    "def mapQueryToDocuments(dataset):\n",
    "    queries = {}\n",
    "    alllabels = np.negative(np.ones(len(dataset[2]), dtype=np.double))\n",
    "    for i in range(0, len(dataset[2])):\n",
    "        if not dataset[2][i] in queries:\n",
    "            queries[dataset[2][i]] = Query(dataset[2][i])\n",
    "        query = queries[dataset[2][i]]\n",
    "        query.addlabel(dataset[1][i])\n",
    "        query.adddoc(dataset[1][i], i)\n",
    "        alllabels[i] = dataset[1][i]\n",
    "        \n",
    "    for q in queries.values():\n",
    "        q.finalize(alllabels)\n",
    "    \n",
    "    return queries, alllabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Rank sample set generation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "from libc.math cimport exp\n",
    "from cython.parallel import prange\n",
    "from cython import boundscheck, wraparound, cdivision\n",
    "from libc.math cimport log2\n",
    "from math import factorial\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc\n",
    "from libc.stdlib cimport free\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double* E(int[:] R, double[:] S) nogil:\n",
    "    cdef int k, j, m = len(R)\n",
    "    cdef double* energy = <double *> malloc(m*sizeof(double))\n",
    "    cdef double res_w_S, factor \n",
    "    if m == 1 or m == 0:\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = 0\n",
    "    else:\n",
    "        factor = 4.0 / (m * ((m - 1)**2))\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            res_w_S = 0.0\n",
    "            for k in range(len(R)):\n",
    "                if k < j: \n",
    "                    res_w_S = res_w_S + (j - k) * (S[R[j]] - S[R[k]])\n",
    "                elif k > j: \n",
    "                    res_w_S = res_w_S + (k - j) * (S[R[k]] - S[R[j]])\n",
    "            energy[j] = factor * res_w_S\n",
    "    return energy\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void P(int[:,:] Rq, double[:] S, double[:,:] probs, double[:] accumulator) nogil:\n",
    "    cdef int rankid, pos, doc\n",
    "    cdef double* en\n",
    "    for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "        en = E(Rq[rankid], S)\n",
    "        for pos in range(len(Rq[rankid])):\n",
    "            doc = Rq[rankid][pos]\n",
    "            probs[doc][rankid] = exp(-en[pos]) # e^{-E}\n",
    "            accumulator[doc] = accumulator[doc] + probs[doc][rankid] # sum(e^{-E})\n",
    "        free(en)\n",
    "    for pos in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][pos]\n",
    "        # e^{-E} / sum(e^{-E})\n",
    "        probs[doc][rankid] = probs[doc][rankid] / accumulator[doc]\n",
    "        \n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                              NDCG EVALUATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cpdef double dcg_k(int[:] rank, double[:] scores, int k) nogil:\n",
    "    cdef double result = 0\n",
    "    cdef int i\n",
    "    for i in prange(k, schedule='static', num_threads=8):\n",
    "        result += (2**scores[rank[i]] - 1) / (log2(i + 2)) # should be i+1, but with numbering starting from 1 instead of 0\n",
    "    return result\n",
    "\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double ndcg_k(int[:] rank, double[:] scores, int k, double ideal) nogil:\n",
    "    if ideal == 0:\n",
    "        return 1.0\n",
    "    return dcg_k(rank, scores, k) / ideal\n",
    "\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                          PERMUTATIONS GENERATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "RANK_SAMPLE_SET_DISTRIBUTIONS = [\n",
    "                                int(.30 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->0\n",
    "                                int(.22 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->1\n",
    "                                int(.18 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->2\n",
    "                                int(.12 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->3\n",
    "                                int(.10 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->0\n",
    "                                int(.06 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->1\n",
    "                                int(.02 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->2\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->0\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->1\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS)  # 1->0\n",
    "                                ]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef bint contained(int[:,:] container, int[:] array) nogil:\n",
    "    cdef bint match\n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    for i in prange(len(container), schedule='static', num_threads=8):\n",
    "        if container[i][0] == -1 or len(container[i]) != len(array):\n",
    "            continue\n",
    "        else:\n",
    "            match = True\n",
    "            for j in range(len(container[i])):\n",
    "                if container[i][j] != array[j]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void setrow(int[:,:] container, int pos, int[:] array) nogil:\n",
    "    cdef int i\n",
    "    for i in prange(len(container[pos]), schedule='static', num_threads=8):\n",
    "        container[pos][i] = array[i]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int[:,:] allPerms(int[:] source, long long fact):\n",
    "    cdef int i = 0\n",
    "    cdef int k\n",
    "    perm = itertools.permutations(source)\n",
    "    cdef int[:,:] result = np.zeros((fact, len(source)), dtype=int)\n",
    "    for p in perm:\n",
    "        for k in range(len(p)):\n",
    "            result[i][k] = p[k]\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "#source: label -> docid*, i: int, j: int, count: int, perms_with_prob: tuple<int> -> float\n",
    "#return: number of not computed permutations\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def perform_permutation(query, int i, int j, int count, int[:,:] perms, int start):\n",
    "    if not i in query.labels or not j in query.labels:\n",
    "        # no swapping possible\n",
    "        return count, start\n",
    "    # find the indexes of the desired labels\n",
    "    i = [k for k in range(len(query.labels)) if query.labels[k] == i][0]\n",
    "    j = [k for k in range(len(query.labels)) if query.labels[k] == j][0]\n",
    "    cdef int c = 0\n",
    "    cdef int _min = min(len(query.docs[i]), len(query.docs[j]))\n",
    "    cdef int amount = max(1, int(_min * .5))\n",
    "    limit = factorial(_min) / (factorial(amount) * factorial(_min - amount))\n",
    "    cdef int k\n",
    "    cdef int d\n",
    "    for k in range(count):\n",
    "        perm = query.docs.copy()\n",
    "        first = random.sample(range(len(query.docs[i])), k=amount)\n",
    "        second = random.sample(range(len(query.docs[j])), k=amount)\n",
    "        for d in range(len(first)):\n",
    "            perm[i][first[d]], perm[j][second[d]] = query.docs[j][second[d]], query.docs[i][first[d]]\n",
    "        p = np.concatenate(perm)\n",
    "        if not contained(perms, p):\n",
    "            setrow(perms, start + c, p)\n",
    "            c += 1\n",
    "            if c == limit:\n",
    "                return count - c, start + c\n",
    "        else:\n",
    "            k -= 1\n",
    "    return 0, start + c\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def process_query(query, alllabels, probs, accumulator):\n",
    "    cdef int carry = 0\n",
    "    fact = factorial(len(query.alldocs))\n",
    "    cdef perms\n",
    "    cdef int last = 0\n",
    "    if fact <= RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS:\n",
    "        # evaluate all possible permutations, each one representing a different ranking\n",
    "        perms = allPerms(query.alldocs, fact)\n",
    "    else:\n",
    "        perms = np.negative(np.ones((RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS, len(query.alldocs)), dtype=int))\n",
    "        # switch the labels of the documents, then sort the documents by label to obtain a ranking\n",
    "        carry, last = perform_permutation(query, 4, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[0], perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[1] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[2] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 3, RANK_SAMPLE_SET_DISTRIBUTIONS[3] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[4] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[5] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[6] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[7] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[8] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 1, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[9] + carry, perms, last)\n",
    "        if carry != 0:\n",
    "            if not query.alldocs in perms:\n",
    "                perms[last] = query.alldocs\n",
    "        perms = perms[perms.max(axis=1)>=0]\n",
    "    query.setperms(perms)  \n",
    "    P(perms, alllabels, probs, accumulator)\n",
    "    cdef double[:] ndcgs = np.zeros(len(perms))\n",
    "    cdef int k = min(10, len(perms[0]))\n",
    "    for i in range(len(perms)):\n",
    "        ndcgs[i] = ndcg_k(perms[i], alllabels, k, query.idealdcg)\n",
    "    query.setndcgs(ndcgs)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/train.txt\n",
      "validation file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/vali.txt\n",
      "test file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/test.txt\n",
      "loading datasets... \n",
      "train dataset loading took 51.5 s\n",
      "validation dataset loading took 17.921875 s\n",
      "test dataset loading took 16.25 s\n",
      "converting datasets to LightGBM format... \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_file, valid_file, test_file = retrieveFileNames()\n",
    "\n",
    "print(\"training file: \" + train_file)\n",
    "print(\"validation file: \" + valid_file)\n",
    "print(\"test file: \" + test_file)\n",
    "    \n",
    "print(\"loading datasets... \")\n",
    "import time\n",
    "start = time.process_time()\n",
    "train_dataset = loadDataset(train_file)\n",
    "print(\"train dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "valid_dataset = loadDataset(valid_file)\n",
    "print(\"validation dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "test_dataset = loadDataset(test_file)\n",
    "print(\"test dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "\n",
    "import itertools\n",
    "print(\"converting datasets to LightGBM format... \")\n",
    "train_lgb = loadLightGBM(train_dataset)\n",
    "valid_lgb = loadLightGBM(valid_dataset)\n",
    "test_lgb = loadLightGBM(test_dataset)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating query-documents mappings...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "print(\"creating query-documents mappings...\")\n",
    "train_id = file_len(train_file)\n",
    "vali_id = file_len(valid_file)\n",
    "test_id = file_len(test_file)\n",
    "ds_to_queries = {}\n",
    "ds_to_queries[train_id] = mapQueryToDocuments(train_dataset)\n",
    "ds_to_queries[vali_id] = mapQueryToDocuments(valid_dataset)\n",
    "ds_to_queries[test_id] = mapQueryToDocuments(test_dataset)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating sample sets...\n",
      "sample set creation took 70.28125 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"creating sample sets...\")\n",
    "start = time.process_time()\n",
    "\n",
    "probs_with_labels = {}\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "for ds_id, queries in ds_to_queries.items():\n",
    "    probs_with_labels[ds_id] = np.zeros((len(queries[1]), RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS))\n",
    "    accumulator = np.zeros(len(queries[1]))\n",
    "    for q in queries[0].values():\n",
    "        process_query(q, queries[1], probs_with_labels[ds_id], accumulator)    \n",
    "    del accumulator\n",
    "    \n",
    "print(\"sample set creation took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "#### BoltzRank logic ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "from libc.math cimport exp\n",
    "from cython.parallel import prange\n",
    "from cython import boundscheck, wraparound, cdivision\n",
    "from libc.math cimport log\n",
    "from math import factorial\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc\n",
    "from libc.stdlib cimport free\n",
    "\n",
    "# Energy function.\n",
    "# params: \n",
    "#  R      the ranking to evaluate. Element i contains the id of the document in position i\n",
    "#  S      the scoring vector. Element i contains the score of the document with id i\n",
    "# returns:\n",
    "#  a c matrix of size (m,2). Row i contains (energy, energy') w.r.t. document i\n",
    "#  NB: call free on the returned matrix.\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double** E(int[:] R, double[:] S) nogil:\n",
    "    cdef int k, j, m = len(R)\n",
    "    cdef double** energy = <double **> malloc(m*sizeof(double*)) # freed at 78\n",
    "    cdef double derivative, first_sum, second_sum, factor\n",
    "    if m == 1 or m == 0:\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = <double *> malloc(2*sizeof(double)) # freed at 77\n",
    "            energy[j][0] = 0\n",
    "            energy[j][1] = 0\n",
    "    else:\n",
    "        factor = 4.0 / (m * ((m - 1)**2))\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = <double *> malloc(2*sizeof(double)) # freed at 77\n",
    "            derivative = 0.0\n",
    "            first_sum = 0.0\n",
    "            second_sum = 0.0\n",
    "            for k in range(len(R)):\n",
    "                if j > k:\n",
    "                    derivative = derivative + (j - k)\n",
    "                    first_sum = first_sum + (j - k) * (S[R[j]] - S[R[k]])\n",
    "                elif k > j: \n",
    "                    derivative = derivative + (j - k)\n",
    "                    second_sum = second_sum + (k - j) * (S[R[k]] - S[R[j]])\n",
    "            energy[j][0] = factor * (first_sum + second_sum)\n",
    "            energy[j][1] = factor * derivative\n",
    "    return energy\n",
    "\n",
    "# Probability function.\n",
    "# params: \n",
    "#  Rq    the rank sample set. Element i contains the i-th ranking, that is, an array of document ids\n",
    "#  S     the scoring vector. Element i contains the score of the document with id i\n",
    "#  probs a c matrix of size (len(S),len(Rq),3). Each row i contains the result of the computation w.r.t. document i. Each row contains a \n",
    "#        matrix (len(Rq),3) containing, for each ranking, a tuple (probability, probability', probability'')\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void P(int[:,:] Rq, double[:] S, double*** probs, double** accumulator) nogil:\n",
    "    cdef int rankid, pos, doc\n",
    "    cdef double** en\n",
    "    \n",
    "    for pos in range(len(Rq[0])):\n",
    "        doc = Rq[0][pos]\n",
    "        probs[doc] = <double **> malloc(len(Rq)*sizeof(double*)) # freed at 138\n",
    "        accumulator[doc] = <double *> malloc(3*sizeof(double*)) # freed at 136\n",
    "        accumulator[doc][0] = 0\n",
    "        accumulator[doc][1] = 0\n",
    "        accumulator[doc][2] = 0\n",
    "        for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "            probs[doc][rankid] = <double *> malloc(3*sizeof(double)) # freed at 138\n",
    "    \n",
    "    for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "        en = E(Rq[rankid], S)\n",
    "        for pos in range(len(Rq[rankid])):\n",
    "            doc = Rq[rankid][pos]\n",
    "            probs[doc][rankid][0] = exp(-en[pos][0]) # e^{-E}\n",
    "            probs[doc][rankid][1] = 0\n",
    "            probs[doc][rankid][2] = en[pos][1] # E'\n",
    "            accumulator[doc][0] = accumulator[doc][0] + probs[doc][rankid][0] # sum(e^{-E})\n",
    "            accumulator[doc][1] = accumulator[doc][1] + (-en[pos][1] * probs[doc][rankid][0]) # sum(-E' * e^{-E})\n",
    "            accumulator[doc][2] = accumulator[doc][2] + ((en[pos][1]**2) * probs[doc][rankid][0]) # sum(E'^2 * e^{-E})\n",
    "            free(en[pos]) # allocated at 28\n",
    "        free(en) # allocated at 24\n",
    "\n",
    "    for pos in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][pos]\n",
    "        # e^{-E} / sum(e^{-E})\n",
    "        probs[doc][rankid][0] = probs[doc][rankid][0] / accumulator[doc][0]\n",
    "        \n",
    "        # -P * (E' + (sum(-E' * e^{-E}) / sum(e^{-E})))\n",
    "        probs[doc][rankid][1] = -probs[doc][rankid][0] * (probs[doc][rankid][2] + (accumulator[doc][1] / accumulator[doc][0]))\n",
    "                \n",
    "        # -P' * (E' + (sum(-E' * e^{-E}) / sum(e^{-E}))) - P * (1 + (sum(E'^2 * e^{-E}) / sum(-E' * e^{-E})) - (sum(-E' * e^{-E})^2 / sum(e^{-E})^2))\n",
    "        probs[doc][rankid][2] = (-probs[doc][rankid][1] * (probs[doc][rankid][2] + (accumulator[doc][1] / accumulator[doc][0]))) \n",
    "        probs[doc][rankid][2] = probs[doc][rankid][2] + (-probs[doc][rankid][0] * (1 + ((accumulator[doc][2] / accumulator[doc][0]) - (accumulator[doc][1]**2 / accumulator[doc][0]**2))))\n",
    "        \n",
    "        free(accumulator[doc]) # allocated at 63\n",
    "        \n",
    "# Loss function.\n",
    "# params: \n",
    "#  Rq                the rank sample set. Element i contains the i-th ranking, that is, an array of document ids\n",
    "#  probs             a c matrix of size (len(S),len(Rq),3). Each row i contains the result of the computation w.r.t. document i. Each row contains a \n",
    "#                    matrix (len(Rq),3) containing, for each ranking, a tuple (probability, probability', probability'')\n",
    "#  ndcgs             a matrix of size (len(Rq)). Each row i contains the ndcg of the ith sample rank\n",
    "#  gains             a c matrix of size (len(S),3) containing, for each document, the evaluated gain with its two derivatives. \n",
    "#  probs_with_labels a matrix of size (len(S),len(Rq)). Each row i contains the result of the computation w.r.t. document i. Each row contains an \n",
    "#                    array (len(Rq)) containing, for each ranking, its probability w.r.t. the target labeling\n",
    "#  entropies         a c matrix of size (len(S),3) containing, for each document, the evaluated cross entropy with its two derivatives. \n",
    "#                    NB the entropy's sign has not yet being flipped \n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "@cdivision(True) \n",
    "cdef void loss_function(int[:,:] Rq, double*** probs, double[:] ndcgs, double** gains, double[:,:] probs_with_labels, double** entropies) nogil:\n",
    "    cdef int i, doc, j\n",
    "    for i in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][i]\n",
    "        gains[doc] = <double*> malloc(3*sizeof(double)) # freed at 163\n",
    "        gains[doc][0] = 0\n",
    "        gains[doc][1] = 0\n",
    "        gains[doc][2] = 0\n",
    "        entropies[doc] = <double*> malloc(3*sizeof(double)) # freed at 164\n",
    "        entropies[doc][0] = 0\n",
    "        entropies[doc][1] = 0\n",
    "        entropies[doc][2] = 0\n",
    "        for j in range(len(Rq)):\n",
    "            gains[doc][0] = gains[doc][0] + probs[doc][j][0] * ndcgs[j]\n",
    "            gains[doc][1] = gains[doc][1] + probs[doc][j][1] * ndcgs[j]\n",
    "            gains[doc][2] = gains[doc][2] + probs[doc][j][2] * ndcgs[j]\n",
    "            \n",
    "            # P(L)log(P(S))\n",
    "            entropies[doc][0] = entropies[doc][0] + probs_with_labels[doc][j] * log(probs[doc][j][0])\n",
    "            # P(L)(P'(S)/P(S))\n",
    "            entropies[doc][1] = entropies[doc][1] + (probs_with_labels[doc][j] * probs[doc][j][1] / probs[doc][j][0])\n",
    "            # P(L)(P(S)P''(S)-P'(S)^2)/P(S)^2\n",
    "            entropies[doc][2] = entropies[doc][2] + (probs_with_labels[doc][j] * ((probs[doc][j][0] * probs[doc][j][2] - probs[doc][j][1]**2) / probs[doc][j][0]**2))\n",
    "                                \n",
    "            free(probs[doc][j]) # allocated at 65\n",
    "\n",
    "        free(probs[doc]) # allocated at 62\n",
    "        \n",
    "# Boltzrank grads and hess evaluation function.\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def eval_boltzrank_grads(queries, S, probs_with_labels): \n",
    "    cdef double lam = .9\n",
    "    cdef double[:] gain = np.ones_like(S)\n",
    "    cdef double[:] hess = np.ones_like(S) \n",
    "    \n",
    "    cdef int i\n",
    "    cdef double*** probs = <double***> malloc(len(S)*sizeof(double**)) # freed at 167\n",
    "    cdef double** accumulator = <double**> malloc(len(S)*sizeof(double*)) # freed at 168\n",
    "    cdef double** gains = <double**> malloc(len(S)*sizeof(double*)) # freed at 165\n",
    "    cdef double** entropies = <double**> malloc(len(S)*sizeof(double*)) # freed at 166\n",
    "    for q in queries.values():\n",
    "        P(q.perms, S, probs, accumulator)\n",
    "        loss_function(q.perms, probs, q.ndcgs, gains, probs_with_labels, entropies)\n",
    "    for i in range(len(gain)):\n",
    "        gain[i] = (lam * gains[i][1]) - ((1-lam) * -entropies[i][1])\n",
    "        hess[i] = (lam * gains[i][2]) - ((1-lam) * -entropies[i][2])\n",
    "        free(gains[i]) # allocated at 108\n",
    "        free(entropies[i]) # allocated at 130\n",
    "    free(gains) # allocated at 154\n",
    "    free(entropies) # allocated at 155\n",
    "    free(probs) # allocated at 152\n",
    "    free(accumulator) # allocated at 153\n",
    "    return gain, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training lightgbm...\n",
      "[1]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[2]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[3]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[4]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[5]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[6]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[7]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[8]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[9]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[10]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[11]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[12]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[13]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[14]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[15]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[16]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[17]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[18]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[19]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[20]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[21]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[22]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[23]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[24]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[25]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[26]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[27]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[28]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[29]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[30]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[31]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[32]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[33]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[34]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[35]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[36]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[37]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[38]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[39]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[40]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-539716b5bbdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m                             \u001b[0mvalid_names\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                             \u001b[0mevals_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                             verbose_eval = 1)\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training took \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" s\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1980\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1981\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"none\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1982\u001b[1;33m             \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1983\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__boost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-539716b5bbdc>\u001b[0m in \u001b[0;36mcompute_grads\u001b[1;34m(preds, train_data)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mtrain_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mprobs_with_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mgain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_boltzrank_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_to_queries\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs_with_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mgain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mhess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_grads(preds, train_data): \n",
    "    global ds_to_queries\n",
    "    global train_id\n",
    "    global probs_with_labels\n",
    "    gain, hess = eval_boltzrank_grads(ds_to_queries[train_id][0], preds, probs_with_labels[train_id])\n",
    "    gain = np.asarray(gain)\n",
    "    hess = np.asarray(hess)\n",
    "    #print(\"PREDS: min \" + str(np.min(preds)) + \" max \" + str(np.max(preds)) + \" mean \" + str(np.mean(preds)) + \" std \" + str(np.std(preds)))\n",
    "    #print(\"GAIN: min \" + str(np.min(gain)) + \" max \" + str(np.max(gain)) + \" mean \" + str(np.mean(gain)) + \" std \" + str(np.std(gain)))\n",
    "    #print(\"HESS: min \" + str(np.min(hess)) + \" max \" + str(np.max(hess)) + \" mean \" + str(np.mean(hess)) + \" std \" + str(np.std(hess)))\n",
    "    return gain, hess\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric': ['ndcg'],# ['None']\n",
    "    'ndcg_eval_at': 10\n",
    "}    \n",
    "\n",
    "print(\"training lightgbm...\")\n",
    "start = time.process_time()\n",
    "lgbm_info = {}\n",
    "lgbm_model = lightgbm.train(params, train_lgb, num_boost_round=100,\n",
    "                            fobj  = compute_grads,\n",
    "                            valid_sets   = [train_lgb, valid_lgb, test_lgb], \n",
    "                            valid_names  = [\"train\", \"valid\", \"test\"],\n",
    "                            evals_result = lgbm_info,\n",
    "                            verbose_eval = 1)\n",
    "print(\"training took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "plt.plot(lgbm_info['train'][METRIC_NAME], label='training')\n",
    "plt.plot(lgbm_info['valid'][METRIC_NAME], label='validation')\n",
    "plt.plot(lgbm_info['test'][METRIC_NAME], label='test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Trees\")\n",
    "plt.ylabel(METRIC_NAME)\n",
    "plt.title(\"Model Error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
