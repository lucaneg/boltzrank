{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import common libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to install lightgbm\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    " - http://lightgbm.readthedocs.io/en/latest/\n",
    " - http://lightgbm.readthedocs.io/en/latest/Python-Intro.html\n",
    " - https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LightGBM and optimize NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset from file\n",
    "\n",
    "train_file = \"C:/opt/kiis-training/MSLR-WEB10K/Fold1/train.txt\"\n",
    "\n",
    "if not os.path.exists(train_file) or not os.path.isfile(train_file):\n",
    "    raise FileNotFoundError(\"'\" + train_file + \"': no such file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html\n",
    "\n",
    "train_data = load_svmlight_file(train_file, query_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"X shape:\", train_data[0].shape )\n",
    "print (\"Y shape:\", train_data[1].shape )\n",
    "print (\"qid shape: \", train_data[2].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it a LightGBM dataset\n",
    "\n",
    "import itertools\n",
    "\n",
    "query_lens = [ sum( 1 for _ in group ) for key, group in itertools.groupby( train_data[2] )  ]\n",
    "train_lgb = lightgbm.Dataset(data=train_data[0], label=train_data[1], group=query_lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "# see http://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "\n",
    "params = {\n",
    "    'objective':'lambdarank', # what to optimize during training\n",
    "    'max_position': 10,      # threshold used in optimizing lamdarank (NDCG)\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 32,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric': ['ndcg'],       # what to use/print for evaluation\n",
    "    'ndcg_eval_at': 10\n",
    "}    \n",
    "\n",
    "lgbm_model = lightgbm.train(params, train_lgb, \n",
    "                            num_boost_round=100,\n",
    "                            valid_sets = [train_lgb], \n",
    "                            verbose_eval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more reasonable setting: train/valid/test\n",
    "\n",
    "import itertools\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html\n",
    "\n",
    "\n",
    "train_file = \"C:/opt/kiis-training/MSLR-WEB10K/Fold1/train.txt\"\n",
    "valid_file = \"C:/opt/kiis-training/MSLR-WEB10K/Fold1/vali.txt\"\n",
    "test_file  = \"C:/opt/kiis-training/MSLR-WEB10K/Fold1/test.txt\"\n",
    "\n",
    "# train\n",
    "raw_data = load_svmlight_file(train_file, query_id=True)\n",
    "query_lens = [ sum( 1 for _ in group ) for key, group in itertools.groupby( raw_data[2] )  ]\n",
    "train_lgb = lightgbm.Dataset(data=raw_data[0], label=raw_data[1], group=query_lens)\n",
    "\n",
    "# valid\n",
    "raw_data = load_svmlight_file(valid_file, query_id=True)\n",
    "query_lens = [ sum( 1 for _ in group ) for key, group in itertools.groupby( raw_data[2] )  ]\n",
    "valid_lgb = lightgbm.Dataset(data=raw_data[0], label=raw_data[1], group=query_lens)\n",
    "\n",
    "# test\n",
    "raw_data = load_svmlight_file(test_file, query_id=True)\n",
    "query_lens = [ sum( 1 for _ in group ) for key, group in itertools.groupby( raw_data[2] )  ]\n",
    "test_lgb = lightgbm.Dataset(data=raw_data[0], label=raw_data[1], group=query_lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'lambdarank', # what to optimize during training\n",
    "    'max_position': 10,      # threshold used in optimizing lamdarank (NDCG)\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric': ['ndcg'],       # what to use/print for evaluation\n",
    "    'ndcg_eval_at': 10\n",
    "}    \n",
    "\n",
    "lgbm_info = {}\n",
    "\n",
    "lgbm_model = lightgbm.train(params, train_lgb, num_boost_round=200,\n",
    "                            valid_sets   = [train_lgb, valid_lgb, test_lgb], \n",
    "                            valid_names  = [\"train\", \"valid\", \"test\"],\n",
    "                            evals_result = lgbm_info,\n",
    "                            verbose_eval = 10)\n",
    "\n",
    "\n",
    "lgbm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "\n",
    "plt.plot(lgbm_info['train']['ndcg@10'], label='training')\n",
    "plt.plot(lgbm_info['valid']['ndcg@10'], label='validation')\n",
    "plt.plot(lgbm_info['test']['ndcg@10'], label='test')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Trees\")\n",
    "plt.ylabel(\"ndcg@10\")\n",
    "plt.title(\"Model Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced example with custom optimization\n",
    "\n",
    "Let's optimize MSE which we know well.\n",
    "\n",
    "- see: https://github.com/Microsoft/LightGBM/blob/master/examples/python-guide/advanced_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "def mse_eval(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    \n",
    "    avg_mse = 0.5 * np.mean( (labels-preds)**2 )\n",
    "    \n",
    "    return 'Custom-MSE', avg_mse, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'lambdarank', # what to optimize during training\n",
    "    'max_position': 10,      # threshold used in optimizing lamdarank (NDCG)\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric': ['None'], #['ndcg'],       # what to use/print for evaluation\n",
    "#    'ndcg_eval_at': 10\n",
    "}    \n",
    "\n",
    "lgbm_info = {}\n",
    "\n",
    "lgbm_model = lightgbm.train(params, train_lgb, num_boost_round=100,\n",
    "                            feval = mse_eval,\n",
    "                            valid_sets   = [train_lgb, valid_lgb, test_lgb], \n",
    "                            valid_names  = [\"train\", \"valid\", \"test\"],\n",
    "                            evals_result = lgbm_info,\n",
    "                            verbose_eval = 10)\n",
    "\n",
    "\n",
    "lgbm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "\n",
    "plt.plot(lgbm_info['train']['Custom-MSE'], label='training')\n",
    "plt.plot(lgbm_info['valid']['Custom-MSE'], label='validation')\n",
    "plt.plot(lgbm_info['test']['Custom-MSE'], label='test')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Trees\")\n",
    "plt.ylabel(\"Custom-MSE\")\n",
    "plt.title(\"Model Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-defined objective function\n",
    "# f(preds: array, train_data: Dataset) -> grad: array, hess: array\n",
    "def mse_grads(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    #grad = labels - preds # this is the neg grad !!!\n",
    "    grad = preds - labels\n",
    "    hess = np.ones_like(grad)\n",
    "    return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "#    'objective':'lambdarank', # what to optimize during training\n",
    "#    'max_position': 10,      # threshold used in optimizing lamdarank (NDCG)\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric': ['None'], #['ndcg'],       # what to use/print for evaluation\n",
    "#    'ndcg_eval_at': 10\n",
    "# try printing ndcg and testing\n",
    "}    \n",
    "\n",
    "lgbm_info = {}\n",
    "\n",
    "lgbm_model = lightgbm.train(params, train_lgb, num_boost_round=100,\n",
    "                            feval = mse_eval,\n",
    "                            fobj  = mse_grads,\n",
    "                            valid_sets   = [train_lgb, valid_lgb, test_lgb], \n",
    "                            valid_names  = [\"train\", \"valid\", \"test\"],\n",
    "                            evals_result = lgbm_info,\n",
    "                            verbose_eval = 10)\n",
    "\n",
    "\n",
    "lgbm_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "\n",
    "plt.plot(lgbm_info['train']['Custom-MSE'], label='training')\n",
    "plt.plot(lgbm_info['valid']['Custom-MSE'], label='validation')\n",
    "plt.plot(lgbm_info['test']['Custom-MSE'], label='test')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Trees\")\n",
    "plt.ylabel(\"Custom-MSE\")\n",
    "plt.title(\"Model Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggestion\n",
    "\n",
    "If you want/need to be fast, use cython to implement your objective and evaluation functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
