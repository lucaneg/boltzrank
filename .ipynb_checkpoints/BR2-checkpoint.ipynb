{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# BoltzRank #\n",
    "## Luca Negrini - Mat. 956516 ##\n",
    "### From \"BoltzRank: Learning to Maximize Expected Ranking Gain\" ###\n",
    "#### Maxims M. Volkovs, Richard S. Zemel ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "#### Initialization ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext cython\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html\n",
    "from sklearn.datasets import load_svmlight_file \n",
    "\n",
    "# datasets available at: \n",
    "# https://www.microsoft.com/en-us/research/project/mslr/\n",
    "DATASET_FOLDER = \"C:/opt/kiis-training/MSLR-WEB10K/Fold1/\"\n",
    "PERM_FOLDER = DATASET_FOLDER + \"perms/\"\n",
    "METRIC_NAME = 'ndcg@10'#'BoltzRank-NDCG@10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Data loading ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureFile(path):\n",
    "    if not os.path.exists(path) or not os.path.isfile(path):\n",
    "        raise FileNotFoundError(\"'\" + path + \"': no such file\")        \n",
    "    return path\n",
    "\n",
    "def retrieveFileNames():\n",
    "    folder = DATASET_FOLDER + '/' if DATASET_FOLDER[-1:] != '/' else DATASET_FOLDER\n",
    "    train_file = ensureFile(folder + \"train.txt\")\n",
    "    valid_file = ensureFile(folder + \"vali.txt\")\n",
    "    test_file = ensureFile(folder + \"test.txt\")\n",
    "    return train_file, valid_file, test_file\n",
    "\n",
    "def loadDataset(path):\n",
    "    return load_svmlight_file(path, query_id=True)\n",
    "\n",
    "def loadLightGBM(svmlight_dataset):\n",
    "    query_lens = [sum(1 for _ in group) for key, group in itertools.groupby(svmlight_dataset[2])]\n",
    "    return lightgbm.Dataset(data=svmlight_dataset[0], label=svmlight_dataset[1], group=query_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, qid):\n",
    "        self.qid = qid\n",
    "        self.labels_to_docs = {}\n",
    "    def addlabel(self, label):\n",
    "        if not label in self.labels_to_docs:\n",
    "            self.labels_to_docs[label] = list()\n",
    "    def adddoc(self, label, doc):\n",
    "        self.labels_to_docs[label].append(doc)\n",
    "    def finalize(self, alllabels):\n",
    "        self.labels = np.zeros(len(self.labels_to_docs.keys()), dtype=int)\n",
    "        self.docs = np.empty(len(self.labels_to_docs.keys()), dtype=object)\n",
    "        i = 0\n",
    "        totaldocs = 0\n",
    "        sorteddict = sorted(self.labels_to_docs.items(), reverse = True)\n",
    "        for label, docs in sorteddict:\n",
    "            self.labels[i] = label\n",
    "            self.docs[i] = np.zeros(len(docs), dtype=int)\n",
    "            for j in range(len(docs)):\n",
    "                self.docs[i][j] = docs[j]\n",
    "            i += 1\n",
    "            totaldocs += len(docs)\n",
    "        self.alldocs = np.concatenate(self.docs)\n",
    "        self.flatlabels = np.zeros(totaldocs, dtype=np.double)\n",
    "        i = 0\n",
    "        for label, docs in sorteddict:\n",
    "            for j in range(len(docs)):\n",
    "                self.flatlabels[i] = label\n",
    "                i += 1       \n",
    "        k = min(10, len(self.alldocs))\n",
    "        self.idealdcg = dcg_k(self.alldocs, alllabels, k) \n",
    "        del self.labels_to_docs\n",
    "    def setperms(self, perms):\n",
    "        self.perms = perms\n",
    "    def setndcgs(self, ndcgs):\n",
    "        self.ndcgs = ndcgs\n",
    "    def __repr__(self):  \n",
    "        return str(self)\n",
    "    def __str__(self):\n",
    "        res = \"Query \" + str(self.qid) + \"[\"\n",
    "        res += \"\\nideal dcg: \" + str(self.idealdcg)\n",
    "        for i in range(len(self.labels)):\n",
    "            res += \"\\n\" + str(self.labels[i]) + \" -> \" + str(self.docs[i])\n",
    "        res += \"]\"\n",
    "        if hasattr(self, 'perms'):\n",
    "            for i in range(len(self.perms)):\n",
    "                res += \"\\n[\" + str(self.perms[i]) + \"] -> dcg: \" + str(self.ndcgs[i])\n",
    "        else:\n",
    "            res += \"\\nNo permutations computed yet\"\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "#  dataset: svmlight_dataset \n",
    "#      the datset to process\n",
    "# returned values:\n",
    "#  query_to_labels_to_documents: dict(int -> dict(float -> list(int)))\n",
    "#      a map containing, for each query in the dataset, the documents (row index in the dataset) provided \n",
    "#      in the input dataset grouped by label\n",
    "#  doc_to_query: dict(document -> query)\n",
    "#      a mapping between document (row index in the dataset) and the relative query\n",
    "def mapQueryToDocuments(dataset):\n",
    "    queries = {}\n",
    "    alllabels = np.negative(np.ones(len(dataset[2]), dtype=np.double))\n",
    "    for i in range(0, len(dataset[2])):\n",
    "        if not dataset[2][i] in queries:\n",
    "            queries[dataset[2][i]] = Query(dataset[2][i])\n",
    "        query = queries[dataset[2][i]]\n",
    "        query.addlabel(dataset[1][i])\n",
    "        query.adddoc(dataset[1][i], i)\n",
    "        alllabels[i] = dataset[1][i]\n",
    "        \n",
    "    for q in queries.values():\n",
    "        q.finalize(alllabels)\n",
    "    \n",
    "    return queries, alllabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Rank sample set generation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "from libc.math cimport exp\n",
    "from cython.parallel import prange\n",
    "from cython import boundscheck, wraparound, cdivision\n",
    "from libc.math cimport log2\n",
    "from math import factorial\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc\n",
    "from libc.stdlib cimport free\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double* E(int[:] R, double[:] S) nogil:\n",
    "    cdef int k, j, m = len(R)\n",
    "    cdef double* energy = <double *> malloc(m*sizeof(double))\n",
    "    cdef double res_w_S, factor \n",
    "    if m == 1 or m == 0:\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = 0\n",
    "    else:\n",
    "        factor = 4.0 / (m * ((m - 1)**2))\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            res_w_S = 0.0\n",
    "            for k in range(len(R)):\n",
    "                if k < j: \n",
    "                    res_w_S = res_w_S + (j - k) * (S[R[j]] - S[R[k]])\n",
    "                elif k > j: \n",
    "                    res_w_S = res_w_S + (k - j) * (S[R[k]] - S[R[j]])\n",
    "            energy[j] = factor * res_w_S\n",
    "    return energy\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void P(int[:,:] Rq, double[:] S, double[:,:] probs, double[:] accumulator) nogil:\n",
    "    cdef int rankid, pos, doc\n",
    "    cdef double* en\n",
    "    for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "        en = E(Rq[rankid], S)\n",
    "        for pos in range(len(Rq[rankid])):\n",
    "            doc = Rq[rankid][pos]\n",
    "            probs[doc][rankid] = exp(-en[pos]) # e^{-E}\n",
    "            accumulator[doc] = accumulator[doc] + probs[doc][rankid] # sum(e^{-E})\n",
    "        free(en)\n",
    "    for pos in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][pos]\n",
    "        # e^{-E} / sum(e^{-E})\n",
    "        probs[doc][rankid] = probs[doc][rankid] / accumulator[doc]\n",
    "        \n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                              NDCG EVALUATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cpdef double dcg_k(int[:] rank, double[:] scores, int k) nogil:\n",
    "    cdef double result = 0\n",
    "    cdef int i\n",
    "    for i in prange(k, schedule='static', num_threads=8):\n",
    "        result += (2**scores[rank[i]] - 1) / (log2(i + 2)) # should be i+1, but with numbering starting from 1 instead of 0\n",
    "    return result\n",
    "\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double ndcg_k(int[:] rank, double[:] scores, int k, double ideal) nogil:\n",
    "    if ideal == 0:\n",
    "        return 1.0\n",
    "    return dcg_k(rank, scores, k) / ideal\n",
    "\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                          PERMUTATIONS GENERATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "RANK_SAMPLE_SET_DISTRIBUTIONS = [\n",
    "                                int(.30 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->0\n",
    "                                int(.22 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->1\n",
    "                                int(.18 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->2\n",
    "                                int(.12 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->3\n",
    "                                int(.10 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->0\n",
    "                                int(.06 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->1\n",
    "                                int(.02 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->2\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->0\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->1\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS)  # 1->0\n",
    "                                ]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef bint contained(int[:,:] container, int[:] array) nogil:\n",
    "    cdef bint match\n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    for i in prange(len(container), schedule='static', num_threads=8):\n",
    "        if container[i][0] == -1 or len(container[i]) != len(array):\n",
    "            continue\n",
    "        else:\n",
    "            match = True\n",
    "            for j in range(len(container[i])):\n",
    "                if container[i][j] != array[j]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void setrow(int[:,:] container, int pos, int[:] array) nogil:\n",
    "    cdef int i\n",
    "    for i in prange(len(container[pos]), schedule='static', num_threads=8):\n",
    "        container[pos][i] = array[i]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int[:,:] allPerms(int[:] source, long long fact):\n",
    "    cdef int i = 0\n",
    "    cdef int k\n",
    "    perm = itertools.permutations(source)\n",
    "    cdef int[:,:] result = np.zeros((fact, len(source)), dtype=int)\n",
    "    for p in perm:\n",
    "        for k in range(len(p)):\n",
    "            result[i][k] = p[k]\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "#source: label -> docid*, i: int, j: int, count: int, perms_with_prob: tuple<int> -> float\n",
    "#return: number of not computed permutations\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def perform_permutation(query, int i, int j, int count, int[:,:] perms, int start):\n",
    "    if not i in query.labels or not j in query.labels:\n",
    "        # no swapping possible\n",
    "        return count, start\n",
    "    # find the indexes of the desired labels\n",
    "    i = [k for k in range(len(query.labels)) if query.labels[k] == i][0]\n",
    "    j = [k for k in range(len(query.labels)) if query.labels[k] == j][0]\n",
    "    cdef int c = 0\n",
    "    cdef int _min = min(len(query.docs[i]), len(query.docs[j]))\n",
    "    cdef int amount = max(1, int(_min * .5))\n",
    "    limit = factorial(_min) / (factorial(amount) * factorial(_min - amount))\n",
    "    cdef int k\n",
    "    cdef int d\n",
    "    for k in range(count):\n",
    "        perm = query.docs.copy()\n",
    "        first = random.sample(range(len(query.docs[i])), k=amount)\n",
    "        second = random.sample(range(len(query.docs[j])), k=amount)\n",
    "        for d in range(len(first)):\n",
    "            perm[i][first[d]], perm[j][second[d]] = query.docs[j][second[d]], query.docs[i][first[d]]\n",
    "        p = np.concatenate(perm)\n",
    "        if not contained(perms, p):\n",
    "            setrow(perms, start + c, p)\n",
    "            c += 1\n",
    "            if c == limit:\n",
    "                return count - c, start + c\n",
    "        else:\n",
    "            k -= 1\n",
    "    return 0, start + c\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def process_query(query, alllabels, probs, accumulator):\n",
    "    cdef int carry = 0\n",
    "    fact = factorial(len(query.alldocs))\n",
    "    cdef perms\n",
    "    cdef int last = 0\n",
    "    if fact <= RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS:\n",
    "        # evaluate all possible permutations, each one representing a different ranking\n",
    "        perms = allPerms(query.alldocs, fact)\n",
    "    else:\n",
    "        perms = np.negative(np.ones((RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS, len(query.alldocs)), dtype=int))\n",
    "        # switch the labels of the documents, then sort the documents by label to obtain a ranking\n",
    "        carry, last = perform_permutation(query, 4, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[0], perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[1] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[2] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 3, RANK_SAMPLE_SET_DISTRIBUTIONS[3] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[4] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[5] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[6] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[7] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[8] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 1, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[9] + carry, perms, last)\n",
    "        if carry != 0:\n",
    "            if not query.alldocs in perms:\n",
    "                perms[last] = query.alldocs\n",
    "        perms = perms[perms.max(axis=1)>=0]\n",
    "    query.setperms(perms)  \n",
    "    P(perms, alllabels, probs, accumulator)\n",
    "    cdef double[:] ndcgs = np.zeros(len(perms))\n",
    "    cdef int k = min(10, len(perms[0]))\n",
    "    for i in range(len(perms)):\n",
    "        ndcgs[i] = ndcg_k(perms[i], alllabels, k, query.idealdcg)\n",
    "    query.setndcgs(ndcgs)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/train.txt\n",
      "validation file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/vali.txt\n",
      "test file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/test.txt\n",
      "loading datasets... \n",
      "train dataset loading took 55.703125 s\n",
      "validation dataset loading took 20.75 s\n",
      "test dataset loading took 18.109375 s\n",
      "converting datasets to LightGBM format... \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_file, valid_file, test_file = retrieveFileNames()\n",
    "\n",
    "print(\"training file: \" + train_file)\n",
    "print(\"validation file: \" + valid_file)\n",
    "print(\"test file: \" + test_file)\n",
    "    \n",
    "print(\"loading datasets... \")\n",
    "import time\n",
    "start = time.process_time()\n",
    "train_dataset = loadDataset(train_file)\n",
    "print(\"train dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "valid_dataset = loadDataset(valid_file)\n",
    "print(\"validation dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "test_dataset = loadDataset(test_file)\n",
    "print(\"test dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "\n",
    "import itertools\n",
    "print(\"converting datasets to LightGBM format... \")\n",
    "train_lgb = loadLightGBM(train_dataset)\n",
    "valid_lgb = loadLightGBM(valid_dataset)\n",
    "test_lgb = loadLightGBM(test_dataset)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating query-documents mappings...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "print(\"creating query-documents mappings...\")\n",
    "train_id = file_len(train_file)\n",
    "vali_id = file_len(valid_file)\n",
    "test_id = file_len(test_file)\n",
    "ds_to_queries = {}\n",
    "ds_to_queries[train_id] = mapQueryToDocuments(train_dataset)\n",
    "ds_to_queries[vali_id] = mapQueryToDocuments(valid_dataset)\n",
    "ds_to_queries[test_id] = mapQueryToDocuments(test_dataset)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating sample sets...\n",
      "sample set creation took 86.21875 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"creating sample sets...\")\n",
    "start = time.process_time()\n",
    "\n",
    "probs_with_labels = {}\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "for ds_id, queries in ds_to_queries.items():\n",
    "    probs_with_labels[ds_id] = np.zeros((len(queries[1]), RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS))\n",
    "    accumulator = np.zeros(len(queries[1]))\n",
    "    for q in queries[0].values():\n",
    "        process_query(q, queries[1], probs_with_labels[ds_id], accumulator)    \n",
    "    del accumulator\n",
    "    \n",
    "print(\"sample set creation took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "#### BoltzRank logic ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "from libc.math cimport exp\n",
    "from cython.parallel import prange\n",
    "from cython import boundscheck, wraparound, cdivision\n",
    "from libc.math cimport log\n",
    "from math import factorial\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc\n",
    "from libc.stdlib cimport free\n",
    "\n",
    "# Energy function.\n",
    "# params: \n",
    "#  R      the ranking to evaluate. Element i contains the id of the document in position i\n",
    "#  S      the scoring vector. Element i contains the score of the document with id i\n",
    "# returns:\n",
    "#  a c matrix of size (m,2). Row i contains (energy, energy') w.r.t. document i\n",
    "#  NB: call free on the returned matrix.\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double** E(int[:] R, double[:] S) nogil:\n",
    "    cdef int k, j, m = len(R)\n",
    "    cdef double** energy = <double **> malloc(m*sizeof(double*)) # freed at 78\n",
    "    cdef double derivative, first_sum, second_sum, factor\n",
    "    if m == 1 or m == 0:\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = <double *> malloc(2*sizeof(double)) # freed at 77\n",
    "            energy[j][0] = 0\n",
    "            energy[j][1] = 0\n",
    "    else:\n",
    "        factor = 4.0 / (m * ((m - 1)**2))\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = <double *> malloc(2*sizeof(double)) # freed at 77\n",
    "            derivative = 0.0\n",
    "            first_sum = 0.0\n",
    "            second_sum = 0.0\n",
    "            for k in range(len(R)):\n",
    "                if j > k:\n",
    "                    derivative = derivative + (j - k)\n",
    "                    first_sum = first_sum + (j - k) * (S[R[j]] - S[R[k]])\n",
    "                elif k > j: \n",
    "                    derivative = derivative + (j - k)\n",
    "                    second_sum = second_sum + (k - j) * (S[R[k]] - S[R[j]])\n",
    "            energy[j][0] = factor * (first_sum + second_sum)\n",
    "            energy[j][1] = factor * derivative\n",
    "    return energy\n",
    "\n",
    "# Probability function.\n",
    "# params: \n",
    "#  Rq    the rank sample set. Element i contains the i-th ranking, that is, an array of document ids\n",
    "#  S     the scoring vector. Element i contains the score of the document with id i\n",
    "#  probs a c matrix of size (len(S),len(Rq),3). Each row i contains the result of the computation w.r.t. document i. Each row contains a \n",
    "#        matrix (len(Rq),3) containing, for each ranking, a tuple (probability, probability', probability'')\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void P(int[:,:] Rq, double[:] S, double*** probs, double** accumulator) nogil:\n",
    "    cdef int rankid, pos, doc\n",
    "    cdef double** en\n",
    "    \n",
    "    for pos in range(len(Rq[0])):\n",
    "        doc = Rq[0][pos]\n",
    "        probs[doc] = <double **> malloc(len(Rq)*sizeof(double*)) # freed at 138\n",
    "        accumulator[doc] = <double *> malloc(3*sizeof(double*)) # freed at 136\n",
    "        accumulator[doc][0] = 0\n",
    "        accumulator[doc][1] = 0\n",
    "        accumulator[doc][2] = 0\n",
    "        for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "            probs[doc][rankid] = <double *> malloc(3*sizeof(double)) # freed at 138\n",
    "    \n",
    "    for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "        en = E(Rq[rankid], S)\n",
    "        for pos in range(len(Rq[rankid])):\n",
    "            doc = Rq[rankid][pos]\n",
    "            probs[doc][rankid][0] = exp(-en[pos][0]) # e^{-E}\n",
    "            probs[doc][rankid][1] = 0\n",
    "            probs[doc][rankid][2] = en[pos][1] # E'\n",
    "            accumulator[doc][0] = accumulator[doc][0] + probs[doc][rankid][0] # sum(e^{-E})\n",
    "            accumulator[doc][1] = accumulator[doc][1] + (-en[pos][1] * probs[doc][rankid][0]) # sum(-E' * e^{-E})\n",
    "            accumulator[doc][2] = accumulator[doc][2] + ((en[pos][1]**2) * probs[doc][rankid][0]) # sum(E'^2 * e^{-E})\n",
    "            free(en[pos]) # allocated at 28\n",
    "        free(en) # allocated at 24\n",
    "\n",
    "    for pos in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][pos]\n",
    "        # e^{-E} / sum(e^{-E})\n",
    "        probs[doc][rankid][0] = probs[doc][rankid][0] / accumulator[doc][0]\n",
    "        \n",
    "        # -P * (E' + (sum(-E' * e^{-E}) / sum(e^{-E})))\n",
    "        probs[doc][rankid][1] = -probs[doc][rankid][0] * (probs[doc][rankid][2] + (accumulator[doc][1] / accumulator[doc][0]))\n",
    "                \n",
    "        # -P' * (E' + (sum(-E' * e^{-E}) / sum(e^{-E}))) - P * (1 + (sum(E'^2 * e^{-E}) / sum(-E' * e^{-E})) - (sum(-E' * e^{-E})^2 / sum(e^{-E})^2))\n",
    "        probs[doc][rankid][2] = (-probs[doc][rankid][1] * (probs[doc][rankid][2] + (accumulator[doc][1] / accumulator[doc][0]))) \n",
    "        probs[doc][rankid][2] = probs[doc][rankid][2] + (-probs[doc][rankid][0] * (1 + ((accumulator[doc][2] / accumulator[doc][0]) - (accumulator[doc][1]**2 / accumulator[doc][0]**2))))\n",
    "        \n",
    "        free(accumulator[doc]) # allocated at 63\n",
    "        \n",
    "# Loss function.\n",
    "# params: \n",
    "#  Rq                the rank sample set. Element i contains the i-th ranking, that is, an array of document ids\n",
    "#  probs             a c matrix of size (len(S),len(Rq),3). Each row i contains the result of the computation w.r.t. document i. Each row contains a \n",
    "#                    matrix (len(Rq),3) containing, for each ranking, a tuple (probability, probability', probability'')\n",
    "#  ndcgs             a matrix of size (len(Rq)). Each row i contains the ndcg of the ith sample rank\n",
    "#  gains             a c matrix of size (len(S),3) containing, for each document, the evaluated gain with its two derivatives. \n",
    "#  probs_with_labels a matrix of size (len(S),len(Rq)). Each row i contains the result of the computation w.r.t. document i. Each row contains an \n",
    "#                    array (len(Rq)) containing, for each ranking, its probability w.r.t. the target labeling\n",
    "#  entropies         a c matrix of size (len(S),3) containing, for each document, the evaluated cross entropy with its two derivatives. \n",
    "#                    NB the entropy's sign has not yet being flipped \n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "@cdivision(True) \n",
    "cdef void loss_function(int[:,:] Rq, double*** probs, double[:] ndcgs, double** gains, double[:,:] probs_with_labels, double** entropies) nogil:\n",
    "    cdef int i, doc, j\n",
    "    for i in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][i]\n",
    "        gains[doc] = <double*> malloc(3*sizeof(double)) # freed at 163\n",
    "        gains[doc][0] = 0\n",
    "        gains[doc][1] = 0\n",
    "        gains[doc][2] = 0\n",
    "        entropies[doc] = <double*> malloc(3*sizeof(double)) # freed at 164\n",
    "        entropies[doc][0] = 0\n",
    "        entropies[doc][1] = 0\n",
    "        entropies[doc][2] = 0\n",
    "        for j in range(len(Rq)):\n",
    "            gains[doc][0] = gains[doc][0] + probs[doc][j][0] * ndcgs[j]\n",
    "            gains[doc][1] = gains[doc][1] + probs[doc][j][1] * ndcgs[j]\n",
    "            gains[doc][2] = gains[doc][2] + probs[doc][j][2] * ndcgs[j]\n",
    "            \n",
    "            # P(L)log(P(S))\n",
    "            entropies[doc][0] = entropies[doc][0] + probs_with_labels[doc][j] * log(probs[doc][j][0])\n",
    "            # P(L)(P'(S)/P(S))\n",
    "            entropies[doc][1] = entropies[doc][1] + (probs_with_labels[doc][j] * probs[doc][j][1] / probs[doc][j][0])\n",
    "            # P(L)(P(S)P''(S)-P'(S)^2)/P(S)^2\n",
    "            entropies[doc][2] = entropies[doc][2] + (probs_with_labels[doc][j] * ((probs[doc][j][0] * probs[doc][j][2] - probs[doc][j][1]**2) / probs[doc][j][0]**2))\n",
    "                                \n",
    "            free(probs[doc][j]) # allocated at 65\n",
    "\n",
    "        free(probs[doc]) # allocated at 62\n",
    "        \n",
    "# Boltzrank grads and hess evaluation function.\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def eval_boltzrank_grads(queries, S, probs_with_labels): \n",
    "    cdef double lam = .9\n",
    "    cdef double[:] gain = np.ones_like(S)\n",
    "    cdef double[:] hess = np.ones_like(S) \n",
    "    \n",
    "    cdef int i\n",
    "    cdef double*** probs = <double***> malloc(len(S)*sizeof(double**)) # freed at 167\n",
    "    cdef double** accumulator = <double**> malloc(len(S)*sizeof(double*)) # freed at 168\n",
    "    cdef double** gains = <double**> malloc(len(S)*sizeof(double*)) # freed at 165\n",
    "    cdef double** entropies = <double**> malloc(len(S)*sizeof(double*)) # freed at 166\n",
    "    for q in queries.values():\n",
    "        P(q.perms, S, probs, accumulator)\n",
    "        loss_function(q.perms, probs, q.ndcgs, gains, probs_with_labels, entropies)\n",
    "    for i in range(len(gain)):\n",
    "        gain[i] = (lam * gains[i][1]) - ((1-lam) * -entropies[i][1])\n",
    "        hess[i] = (lam * gains[i][2]) - ((1-lam) * -entropies[i][2])\n",
    "        free(gains[i]) # allocated at 108\n",
    "        free(entropies[i]) # allocated at 130\n",
    "    free(gains) # allocated at 154\n",
    "    free(entropies) # allocated at 155\n",
    "    free(probs) # allocated at 152\n",
    "    free(accumulator) # allocated at 153\n",
    "    return gain, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training lightgbm...\n",
      "[1]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[2]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[3]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[4]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[5]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[6]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[7]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[8]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[9]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[10]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[11]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[12]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[13]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[14]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[15]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[16]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[17]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[18]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[19]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[20]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[21]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[22]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[23]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[24]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[25]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[26]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[27]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[28]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[29]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[30]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[31]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[32]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[33]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[34]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[35]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[36]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[37]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[38]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[39]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[40]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[41]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[42]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[43]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[44]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[45]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[46]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[47]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[48]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[49]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[50]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[51]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[52]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[53]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[54]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[55]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[56]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[57]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[58]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[59]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[60]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[61]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[62]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[63]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[64]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[65]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[66]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[67]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[68]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[69]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[70]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[71]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[72]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[73]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[74]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[75]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[76]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[77]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[78]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[79]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[80]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[81]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[82]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[83]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[84]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[85]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[86]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[87]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[88]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[89]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[90]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[91]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[92]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[93]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[94]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[95]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[96]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[97]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[98]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[99]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "[100]\ttrain's ndcg@10: 0.210944\tvalid's ndcg@10: 0.214492\ttest's ndcg@10: 0.209852\n",
      "training took 3543.625 s\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Model Error')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_grads(preds, train_data): \n",
    "    global ds_to_queries\n",
    "    global train_id\n",
    "    global probs_with_labels\n",
    "    gain, hess = eval_boltzrank_grads(ds_to_queries[train_id][0], preds, probs_with_labels[train_id])\n",
    "    gain = np.asarray(gain)\n",
    "    hess = np.asarray(hess)\n",
    "    #print(\"PREDS: min \" + str(np.min(preds)) + \" max \" + str(np.max(preds)) + \" mean \" + str(np.mean(preds)) + \" std \" + str(np.std(preds)))\n",
    "    #print(\"GAIN: min \" + str(np.min(gain)) + \" max \" + str(np.max(gain)) + \" mean \" + str(np.mean(gain)) + \" std \" + str(np.std(gain)))\n",
    "    #print(\"HESS: min \" + str(np.min(hess)) + \" max \" + str(np.max(hess)) + \" mean \" + str(np.mean(hess)) + \" std \" + str(np.std(hess)))\n",
    "    return gain, hess\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric': ['ndcg'],# ['None']\n",
    "    'ndcg_eval_at': 10\n",
    "}    \n",
    "\n",
    "print(\"training lightgbm...\")\n",
    "start = time.process_time()\n",
    "lgbm_info = {}\n",
    "lgbm_model = lightgbm.train(params, train_lgb, num_boost_round=100,\n",
    "                            fobj  = compute_grads,\n",
    "                            valid_sets   = [train_lgb, valid_lgb, test_lgb], \n",
    "                            valid_names  = [\"train\", \"valid\", \"test\"],\n",
    "                            evals_result = lgbm_info,\n",
    "                            verbose_eval = 1)\n",
    "print(\"training took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "plt.plot(lgbm_info['train'][METRIC_NAME], label='training')\n",
    "plt.plot(lgbm_info['valid'][METRIC_NAME], label='validation')\n",
    "plt.plot(lgbm_info['test'][METRIC_NAME], label='test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Trees\")\n",
    "plt.ylabel(METRIC_NAME)\n",
    "plt.title(\"Model Error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
