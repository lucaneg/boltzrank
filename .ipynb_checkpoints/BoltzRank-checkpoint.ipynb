{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>BoltzRank</h1>\n",
    "<h2>Luca Negrini - Mat. 956516</h2>\n",
    "<h3>From \"BoltzRank: Learning to Maximize Expected Ranking Gain\"</h3>\n",
    "<h4>Maxims M. Volkovs, Richard S. Zemel</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "# install lightgbm (required only on first run)\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install lightgbm\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html\n",
    "from sklearn.datasets import load_svmlight_file \n",
    "\n",
    "# datasets available at: \n",
    "# https://www.microsoft.com/en-us/research/project/mslr/\n",
    "DATASET_FOLDER = \"C:/opt/kiis-training/MSLR-WEB10K/Fold0/\"\n",
    "PERM_FOLDER = DATASET_FOLDER + \"perms/\"\n",
    "METRIC_NAME = 'Custom-MSE'\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "RANK_SAMPLE_SET_DISTRIBUTIONS = [\n",
    "                                int(.20 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->0\n",
    "                                int(.18 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->1\n",
    "                                int(.14 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->2\n",
    "                                int(.08 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->3\n",
    "                                int(.14 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->0\n",
    "                                int(.12 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->1\n",
    "                                int(.06 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->2\n",
    "                                int(.04 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->0\n",
    "                                int(.02 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->1\n",
    "                                int(.02 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS)  # 1->0\n",
    "                                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "def timed(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(*args, **kwds):\n",
    "        print(\"%s [start]\" % (f.__name__))\n",
    "        start = time()\n",
    "        result = f(*args, **kwds)\n",
    "        elapsed = time() - start\n",
    "        print(\"%s [stop]: %d sec\" % (f.__name__, elapsed))\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load all data\n",
    "#\n",
    "\n",
    "def ensureFile(path):\n",
    "    if not os.path.exists(path) or not os.path.isfile(path):\n",
    "        raise FileNotFoundError(\"'\" + path + \"': no such file\")\n",
    "        \n",
    "    return path\n",
    "\n",
    "def retrieveFileNames():\n",
    "    folder = DATASET_FOLDER + '/' if DATASET_FOLDER[-1:] != '/' else DATASET_FOLDER\n",
    "    train_file = ensureFile(folder + \"train.txt\")\n",
    "    valid_file = ensureFile(folder + \"vali.txt\")\n",
    "    test_file = ensureFile(folder + \"test.txt\")\n",
    "        \n",
    "    return train_file, valid_file, test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Convert data to lightGBM format\n",
    "#\n",
    "\n",
    "@timed\n",
    "def loadDataset(path):\n",
    "    return load_svmlight_file(path, query_id=True)\n",
    "\n",
    "@timed\n",
    "def loadLightGBM(svmlight_dataset):\n",
    "    query_lens = [sum(1 for _ in group) for key, group in itertools.groupby(svmlight_dataset[2])]\n",
    "    return lightgbm.Dataset(data=svmlight_dataset[0], label=svmlight_dataset[1], group=query_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timed\n",
    "def mapQueryToDocuments(dataset):\n",
    "    query_to_labels_to_documents = {} # query -> label -> document*\n",
    "    doc_to_query = {} # document -> query\n",
    "    for i in range(0, len(dataset[2])):\n",
    "        if not dataset[2][i] in query_to_labels_to_documents:\n",
    "            query_to_labels_to_documents[dataset[2][i]] = {}\n",
    "        if not dataset[1][i] in query_to_labels_to_documents[dataset[2][i]]:\n",
    "            query_to_labels_to_documents[dataset[2][i]][dataset[1][i]] = list()\n",
    "        query_to_labels_to_documents[dataset[2][i]][dataset[1][i]].append(i)\n",
    "        doc_to_query[i] = dataset[2][i]\n",
    "        \n",
    "    return query_to_labels_to_documents, doc_to_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_q(x, m):\n",
    "    return (2 * x) / (m - 1)\n",
    "\n",
    "# rank: docid*, scores: label -> docid* => energy\n",
    "def energy(rank, scores):\n",
    "    m = len(rank)\n",
    "    if m == 1:\n",
    "        return 1\n",
    "    factor = 2 / (m * (m - 1))\n",
    "    res = 0\n",
    "    for j in range(m):\n",
    "        for k in range(j, m):\n",
    "            score_j = [l for l,docs in scores.items() if rank[j] in docs]\n",
    "            score_k = [l for l,docs in scores.items() if rank[k] in docs]\n",
    "            res += g_q(j - k, m) * (score_j[0] - score_k[0])\n",
    "    return factor * res\n",
    "\n",
    "# sample: docid**, rank: docid*, scores: label -> docid* => probability\n",
    "def approx_rank_probability(sample, rank, scores):\n",
    "    prob = np.exp(-energy(rank, scores))\n",
    "    norm = 0\n",
    "    for r in sample:\n",
    "        norm += np.exp(-energy(r, scores))\n",
    "    return prob / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: label -> docid*, i: int, j: int, count: int, perms_with_prob: tuple<int> -> float\n",
    "#return: number of not computed permutations\n",
    "def perform_permutation(source,i,j,count,perms_with_prob):\n",
    "    if not i in source or len(source[i]) == 0 or not j in source or len(source[j]) == 0:\n",
    "        # no swapping possible\n",
    "        return count\n",
    "    c = 0\n",
    "    _min = min(len(source[i]), len(source[j]))\n",
    "    limit = math.factorial(_min)\n",
    "    amount = max(1, int(_min * .5))\n",
    "    for k in range(count):\n",
    "        perm = source.copy()\n",
    "        first = random.sample(perm[i], k=amount)\n",
    "        second = random.sample(perm[j], k=amount)\n",
    "        for d in first:\n",
    "            perm[i].remove(d)\n",
    "            perm[j].append(d)\n",
    "        for d in second:\n",
    "            perm[j].remove(d)\n",
    "            perm[i].append(d)\n",
    "\n",
    "        p = tuple(merge(perm))\n",
    "        if not p in perms_with_prob:\n",
    "            perms_with_prob[p] = 0 # we save the permutation for later: to evaluate the probabilities we need the whole sample\n",
    "            c += 1\n",
    "            if c == limit:\n",
    "                return count - c # we generated all possible permutations\n",
    "        else:\n",
    "            k -= 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(dictionary):\n",
    "    result = []\n",
    "    for key, value in sorted(dictionary.items(),reverse=True):\n",
    "        result.extend(value)\n",
    "    return result\n",
    "\n",
    "def perm_filename(id):\n",
    "    return PERM_FOLDER + \"quid\" + str(id) + \"perm.pkl\"\n",
    "\n",
    "#@timed\n",
    "def process_query(t):\n",
    "    query = t[0]\n",
    "    values = t[1]\n",
    "    merged = merge(values)\n",
    "    if math.factorial(len(merged)) <= RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS:\n",
    "        # evaluate all possible permutations, each one representing a different ranking\n",
    "        perms_with_prob = {}\n",
    "        sample = list(itertools.permutations(merged))\n",
    "        for p in sample:\n",
    "            perms_with_prob[p] = approx_rank_probability(sample, p, values)\n",
    "        with open(perm_filename(query), \"wb\") as out:\n",
    "            pickle.dump(perms_with_prob, out)\n",
    "    else:\n",
    "        perms_with_prob = {}\n",
    "        # switch the labels of the documents, then sort the documents by label to obtain a ranking\n",
    "        carry = perform_permutation(values, 4, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[0], perms_with_prob)\n",
    "        carry = perform_permutation(values, 4, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[1] + carry, perms_with_prob)\n",
    "        carry = perform_permutation(values, 4, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[2] + carry, perms_with_prob)\n",
    "        carry = perform_permutation(values, 4, 3, RANK_SAMPLE_SET_DISTRIBUTIONS[3] + carry, perms_with_prob)\n",
    "        carry = perform_permutation(values, 3, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[4] + carry, perms_with_prob)\n",
    "        carry = perform_permutation(values, 3, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[5] + carry, perms_with_prob)\n",
    "        carry = perform_permutation(values, 3, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[6] + carry, perms_with_prob)\n",
    "        carry = perform_permutation(values, 2, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[7] + carry, perms_with_prob)\n",
    "        carry = perform_permutation(values, 2, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[8] + carry, perms_with_prob)\n",
    "        carry = perform_permutation(values, 1, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[9] + carry, perms_with_prob)\n",
    "        if carry != 0:\n",
    "            print(\"unable to perform \" + str(carry) + \" permutations in query \" + str(query))\n",
    "        sample = perms_with_prob.keys()\n",
    "        for p in sample:\n",
    "            perms_with_prob[p] = approx_rank_probability(sample, p, values)\n",
    "        return (query, perms_with_prob)\n",
    "        #with open(perm_filename(query), \"wb\") as out:\n",
    "        #    pickle.dump(perms_with_prob, out)   \n",
    "        \n",
    "@timed\n",
    "def createSampleSets(query_to_labels_to_documents):\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    result_list = Parallel(n_jobs=num_cores)(delayed(process_query)((query, values)) for query, values in query_to_labels_to_documents.items())\n",
    "    return result_list\n",
    "\n",
    "@timed\n",
    "def dumpSampleSet(result_list):\n",
    "    for query, perms in result_list:\n",
    "        with open(perm_filename(query), \"wb\") as out:\n",
    "            pickle.dump(perms, out)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: C:/opt/kiis-training/MSLR-WEB10K/Fold0/train.txt\n",
      "validation file: C:/opt/kiis-training/MSLR-WEB10K/Fold0/vali.txt\n",
      "test file: C:/opt/kiis-training/MSLR-WEB10K/Fold0/test.txt\n",
      "loading datasets... \n",
      "loadDataset [start]\n",
      "loadDataset [stop]: 3 sec\n",
      "loadDataset [start]\n",
      "loadDataset [stop]: 3 sec\n",
      "loadDataset [start]\n",
      "loadDataset [stop]: 3 sec\n",
      "converting datasets to LightGBM format... \n",
      "loadLightGBM [start]\n",
      "loadLightGBM [stop]: 0 sec\n",
      "loadLightGBM [start]\n",
      "loadLightGBM [stop]: 0 sec\n",
      "loadLightGBM [start]\n",
      "loadLightGBM [stop]: 0 sec\n",
      "creating query-documents mappings...\n",
      "mapQueryToDocuments [start]\n",
      "mapQueryToDocuments [stop]: 0 sec\n"
     ]
    }
   ],
   "source": [
    "train_file, valid_file, test_file = retrieveFileNames()\n",
    "\n",
    "print(\"training file: \" + train_file)\n",
    "print(\"validation file: \" + valid_file)\n",
    "print(\"test file: \" + test_file)\n",
    "    \n",
    "print(\"loading datasets... \")\n",
    "train_dataset = loadDataset(train_file)\n",
    "valid_dataset = loadDataset(valid_file)\n",
    "test_dataset = loadDataset(test_file)\n",
    "\n",
    "print(\"converting datasets to LightGBM format... \")\n",
    "train_lgb = loadLightGBM(train_dataset)\n",
    "valid_lgb = loadLightGBM(valid_dataset)\n",
    "test_lgb = loadLightGBM(test_dataset)\n",
    "\n",
    "print(\"creating query-documents mappings...\")\n",
    "query_to_labels_to_documents, doc_to_query = mapQueryToDocuments(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating sample sets...\n",
      "createSampleSets [start]\n",
      "createSampleSets [stop]: 147 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"creating sample sets...\")\n",
    "result_list = {}\n",
    "if not os.path.isdir(PERM_FOLDER):\n",
    "    os.mkdir(PERM_FOLDER)\n",
    "    result_list = dict(createSampleSets(query_to_labels_to_documents))\n",
    "    #dumpSampleSet(result_list)\n",
    "else:\n",
    "    print(PERM_FOLDER + \" already exists, skipping rank sample sets creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Define evaluation metric and objective function\n",
    "#\n",
    "\n",
    "# current predictions, dataset => name, score, true iff higher means better\n",
    "def mse_eval(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    avg_mse = 0.5 * np.mean( (labels-preds)**2 )\n",
    "    return METRIC_NAME, avg_mse, False\n",
    "\n",
    "def cross_entropy(query,scores):\n",
    "    global result_list\n",
    "    result = 0\n",
    "   # with open(perm_filename(query), \"rb\") as read:\n",
    "    #    samples = pickle.load(read)\n",
    "    samples = result_list[query]\n",
    "    for sample, prob in samples.items():\n",
    "        result += prob * np.log(approx_rank_probability(samples, sample, scores))\n",
    "    return query, result # should be -result\n",
    "\n",
    "# current predictions, dataset => first order derivative, second order derivative\n",
    "def mse_grads(preds, train_data): \n",
    "    labels = train_data.get_label()\n",
    "    #lam = .9\n",
    "    #lam * something * (1-lam)*cross_entropy(i, preds)\n",
    "    \n",
    "    query_to_scores = {} # query -> label -> docid*\n",
    "    for d in range(len(preds)):\n",
    "        query = doc_to_query[d]\n",
    "        if not query in query_to_scores:\n",
    "            query_to_scores[query] = {}\n",
    "        if not preds[d] in query_to_scores[query]:\n",
    "            query_to_scores[query][preds[d]] = list()\n",
    "        query_to_scores[query][preds[d]].append(d)\n",
    "\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    tmp = Parallel(n_jobs=num_cores)(delayed(cross_entropy)(query, query_to_scores[query]) for query in query_to_scores)\n",
    "    query_to_entropy = dict(tmp)\n",
    "#    query_to_entropy = {}\n",
    "#    for query in query_to_scores:      \n",
    "#        query_to_entropy[query] = cross_entropy(query, query_to_scores[query])\n",
    "\n",
    "    gain = np.zeros_like(preds)\n",
    "    for i in range(len(gain)):\n",
    "        gain[i] = query_to_entropy[doc_to_query[i]]\n",
    "    #grad = preds - labels \n",
    "    hess = np.ones_like(gain) \n",
    "    return gain, hess    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttrain's Custom-MSE: 0.39424\tvalid's Custom-MSE: 0.410413\ttest's Custom-MSE: 0.42264\n",
      "[2]\ttrain's Custom-MSE: 0.337615\tvalid's Custom-MSE: 0.353015\ttest's Custom-MSE: 0.363331\n",
      "[3]\ttrain's Custom-MSE: 0.307503\tvalid's Custom-MSE: 0.32301\ttest's Custom-MSE: 0.330802\n",
      "[4]\ttrain's Custom-MSE: 0.303909\tvalid's Custom-MSE: 0.320403\ttest's Custom-MSE: 0.325058\n",
      "[5]\ttrain's Custom-MSE: 0.326836\tvalid's Custom-MSE: 0.345196\ttest's Custom-MSE: 0.346101\n",
      "[6]\ttrain's Custom-MSE: 0.376286\tvalid's Custom-MSE: 0.397394\ttest's Custom-MSE: 0.393937\n",
      "[7]\ttrain's Custom-MSE: 0.452265\tvalid's Custom-MSE: 0.477002\ttest's Custom-MSE: 0.468567\n",
      "[8]\ttrain's Custom-MSE: 0.554775\tvalid's Custom-MSE: 0.584022\ttest's Custom-MSE: 0.569998\n",
      "[9]\ttrain's Custom-MSE: 0.683821\tvalid's Custom-MSE: 0.71846\ttest's Custom-MSE: 0.698232\n",
      "[10]\ttrain's Custom-MSE: 0.839406\tvalid's Custom-MSE: 0.880319\ttest's Custom-MSE: 0.853274\n",
      "[11]\ttrain's Custom-MSE: 1.02153\tvalid's Custom-MSE: 1.0696\ttest's Custom-MSE: 1.03513\n",
      "[12]\ttrain's Custom-MSE: 1.23021\tvalid's Custom-MSE: 1.28632\ttest's Custom-MSE: 1.2438\n",
      "[13]\ttrain's Custom-MSE: 1.46543\tvalid's Custom-MSE: 1.53047\ttest's Custom-MSE: 1.47929\n",
      "[14]\ttrain's Custom-MSE: 1.72721\tvalid's Custom-MSE: 1.80206\ttest's Custom-MSE: 1.7416\n",
      "[15]\ttrain's Custom-MSE: 2.01555\tvalid's Custom-MSE: 2.10109\ttest's Custom-MSE: 2.03075\n",
      "[16]\ttrain's Custom-MSE: 2.33046\tvalid's Custom-MSE: 2.42757\ttest's Custom-MSE: 2.34673\n",
      "[17]\ttrain's Custom-MSE: 2.67193\tvalid's Custom-MSE: 2.7815\ttest's Custom-MSE: 2.68954\n",
      "[18]\ttrain's Custom-MSE: 3.03997\tvalid's Custom-MSE: 3.16289\ttest's Custom-MSE: 3.0592\n",
      "[19]\ttrain's Custom-MSE: 3.43459\tvalid's Custom-MSE: 3.57174\ttest's Custom-MSE: 3.45571\n",
      "[20]\ttrain's Custom-MSE: 3.85578\tvalid's Custom-MSE: 4.00806\ttest's Custom-MSE: 3.87907\n",
      "[21]\ttrain's Custom-MSE: 4.30356\tvalid's Custom-MSE: 4.47185\ttest's Custom-MSE: 4.32928\n",
      "[22]\ttrain's Custom-MSE: 4.77794\tvalid's Custom-MSE: 4.96311\ttest's Custom-MSE: 4.80636\n",
      "[23]\ttrain's Custom-MSE: 5.2789\tvalid's Custom-MSE: 5.48186\ttest's Custom-MSE: 5.3103\n",
      "[24]\ttrain's Custom-MSE: 5.80646\tvalid's Custom-MSE: 6.02809\ttest's Custom-MSE: 5.84111\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-cef9ec8efd8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                             \u001b[0mvalid_names\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                             \u001b[0mevals_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgbm_info\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                             verbose_eval = 1)\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;31m# lgbm_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1980\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1981\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_parameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"none\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1982\u001b[1;33m             \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__inner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1983\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__boost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-65-a140619b163b>\u001b[0m in \u001b[0;36mmse_grads\u001b[1;34m(preds, train_data)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mnum_cores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_to_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery_to_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mquery_to_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#    query_to_entropy = {}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#\n",
    "# Train the model\n",
    "#\n",
    "\n",
    "params = {\n",
    "#    'objective':'lambdarank', # what to optimize during training\n",
    "#    'max_position': 10,      # threshold used in optimizing lamdarank (NDCG)\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric': ['None'], #['ndcg'],       # what to use/print for evaluation\n",
    "#    'ndcg_eval_at': 10\n",
    "# try printing ndcg and testing\n",
    "}    \n",
    "\n",
    "lgbm_info = {}\n",
    "lgbm_model = lightgbm.train(params, train_lgb, num_boost_round=100,\n",
    "                            feval = mse_eval,\n",
    "                            fobj  = mse_grads,\n",
    "                            valid_sets   = [train_lgb, valid_lgb, test_lgb], \n",
    "                            valid_names  = [\"train\", \"valid\", \"test\"],\n",
    "                            evals_result = lgbm_info,\n",
    "                            verbose_eval = 1)\n",
    "# lgbm_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plot the results\n",
    "#\n",
    "\n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "\n",
    "plt.plot(lgbm_info['train'][METRIC_NAME], label='training')\n",
    "plt.plot(lgbm_info['valid'][METRIC_NAME], label='validation')\n",
    "plt.plot(lgbm_info['test'][METRIC_NAME], label='test')\n",
    "\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Trees\")\n",
    "plt.ylabel(METRIC_NAME)\n",
    "plt.title(\"Model Error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
