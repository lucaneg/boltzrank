{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# BoltzRank #\n",
    "## Luca Negrini - Mat. 956516 ##\n",
    "### From \"BoltzRank: Learning to Maximize Expected Ranking Gain\" ###\n",
    "#### Maxims M. Volkovs, Richard S. Zemel ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "#### Initialization ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "%load_ext cython\n",
    "\n",
    "# install lightgbm (required only on first run)\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install lightgbm\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html\n",
    "from sklearn.datasets import load_svmlight_file \n",
    "\n",
    "# datasets available at: \n",
    "# https://www.microsoft.com/en-us/research/project/mslr/\n",
    "DATASET_FOLDER = \"C:/opt/kiis-training/MSLR-WEB10K/Fold1/\"\n",
    "PERM_FOLDER = DATASET_FOLDER + \"perms/\"\n",
    "METRIC_NAME = 'BoltzRank-NDCG@10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Data loading ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureFile(path):\n",
    "    if not os.path.exists(path) or not os.path.isfile(path):\n",
    "        raise FileNotFoundError(\"'\" + path + \"': no such file\")        \n",
    "    return path\n",
    "\n",
    "def retrieveFileNames():\n",
    "    folder = DATASET_FOLDER + '/' if DATASET_FOLDER[-1:] != '/' else DATASET_FOLDER\n",
    "    train_file = ensureFile(folder + \"train.txt\")\n",
    "    valid_file = ensureFile(folder + \"vali.txt\")\n",
    "    test_file = ensureFile(folder + \"test.txt\")\n",
    "    return train_file, valid_file, test_file\n",
    "\n",
    "def loadDataset(path):\n",
    "    return load_svmlight_file(path, query_id=True)\n",
    "\n",
    "def loadLightGBM(svmlight_dataset):\n",
    "    query_lens = [sum(1 for _ in group) for key, group in itertools.groupby(svmlight_dataset[2])]\n",
    "    return lightgbm.Dataset(data=svmlight_dataset[0], label=svmlight_dataset[1], group=query_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, qid):\n",
    "        self.qid = qid\n",
    "        self.labels_to_docs = {}\n",
    "    def addlabel(self, label):\n",
    "        if not label in self.labels_to_docs:\n",
    "            self.labels_to_docs[label] = list()\n",
    "    def adddoc(self, label, doc):\n",
    "        self.labels_to_docs[label].append(doc)\n",
    "    def finalize(self, alllabels):\n",
    "        self.labels = np.zeros(len(self.labels_to_docs.keys()), dtype=int)\n",
    "        self.docs = np.empty(len(self.labels_to_docs.keys()), dtype=object)\n",
    "        i = 0\n",
    "        totaldocs = 0\n",
    "        sorteddict = sorted(self.labels_to_docs.items(), reverse = True)\n",
    "        for label, docs in sorteddict:\n",
    "            self.labels[i] = label\n",
    "            self.docs[i] = np.zeros(len(docs), dtype=int)\n",
    "            for j in range(len(docs)):\n",
    "                self.docs[i][j] = docs[j]\n",
    "            i += 1\n",
    "            totaldocs += len(docs)\n",
    "        self.alldocs = np.concatenate(self.docs)\n",
    "        self.flatlabels = np.zeros(totaldocs, dtype=np.double)\n",
    "        i = 0\n",
    "        for label, docs in sorteddict:\n",
    "            for j in range(len(docs)):\n",
    "                self.flatlabels[i] = label\n",
    "                i += 1       \n",
    "        k = min(10, len(self.alldocs))\n",
    "        self.idealdcg = dcg_k(self.alldocs, alllabels, k) \n",
    "        del self.labels_to_docs\n",
    "    def setperms(self, perms):\n",
    "        self.perms = perms\n",
    "    def setprobs(self, probs):\n",
    "        self.probs = probs\n",
    "    def setndcgs(self, ndcgs):\n",
    "        self.ndcgs = ndcgs\n",
    "    def __repr__(self):  \n",
    "        return str(self)\n",
    "    def __str__(self):\n",
    "        res = \"Query \" + str(self.qid) + \"[\"\n",
    "        res += \"\\nideal dcg: \" + str(self.idealdcg)\n",
    "        for i in range(len(self.labels)):\n",
    "            res += \"\\n\" + str(self.labels[i]) + \" -> \" + str(self.docs[i])\n",
    "        res += \"]\"\n",
    "        if hasattr(self, 'perms'):\n",
    "            for i in range(len(self.perms)):\n",
    "                res += \"\\n[\" + str(self.perms[i]) + \"] -> p: \" + str(self.probs[i]) + \", dcg: \" + str(self.ndcgs[i])\n",
    "        else:\n",
    "            res += \"\\nNo permutations computed yet\"\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "#  dataset: svmlight_dataset \n",
    "#      the datset to process\n",
    "# returned values:\n",
    "#  query_to_labels_to_documents: dict(int -> dict(float -> list(int)))\n",
    "#      a map containing, for each query in the dataset, the documents (row index in the dataset) provided \n",
    "#      in the input dataset grouped by label\n",
    "#  doc_to_query: dict(document -> query)\n",
    "#      a mapping between document (row index in the dataset) and the relative query\n",
    "def mapQueryToDocuments(dataset):\n",
    "    queries = {}\n",
    "    alllabels = np.negative(np.ones(len(dataset[2]), dtype=np.double))\n",
    "    for i in range(0, len(dataset[2])):\n",
    "        if not dataset[2][i] in queries:\n",
    "            queries[dataset[2][i]] = Query(dataset[2][i])\n",
    "        query = queries[dataset[2][i]]\n",
    "        query.addlabel(dataset[1][i])\n",
    "        query.adddoc(dataset[1][i], i)\n",
    "        alllabels[i] = dataset[1][i]\n",
    "        \n",
    "    for q in queries.values():\n",
    "        q.finalize(alllabels)\n",
    "    \n",
    "    return queries, alllabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### BoltzRank logic in Cython ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "from libc.math cimport exp\n",
    "from cython.parallel import prange\n",
    "from cython import boundscheck, wraparound\n",
    "from libc.math cimport log, log2\n",
    "from math import factorial\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from libc.stdio cimport printf\n",
    "\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                              NDCG EVALUATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cpdef double dcg_k(int[:] rank, double[:] scores, int k) nogil:\n",
    "    cdef double result = 0\n",
    "    cdef int i\n",
    "    for i in prange(k, schedule='static', num_threads=8):\n",
    "        result += (2**scores[rank[i]] - 1) / (log2(i + 2)) # should be i+1, but with numbering starting from 1 instead of 0\n",
    "    return result\n",
    "\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double ndcg_k(int[:] rank, double[:] scores, int k, double ideal) nogil:\n",
    "    if ideal == 0:\n",
    "        return 1.0\n",
    "    return dcg_k(rank, scores, k) / ideal\n",
    "\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                          PERMUTATIONS GENERATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "RANK_SAMPLE_SET_DISTRIBUTIONS = [\n",
    "                                int(.30 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->0\n",
    "                                int(.22 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->1\n",
    "                                int(.18 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->2\n",
    "                                int(.12 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->3\n",
    "                                int(.10 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->0\n",
    "                                int(.06 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->1\n",
    "                                int(.02 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->2\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->0\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->1\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS)  # 1->0\n",
    "                                ]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef bint contained(int[:,:] container, int[:] array) nogil:\n",
    "    cdef bint match\n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    for i in prange(len(container), schedule='static', num_threads=8):\n",
    "        if container[i][0] == -1 or len(container[i]) != len(array):\n",
    "            continue\n",
    "        else:\n",
    "            match = True\n",
    "            for j in range(len(container[i])):\n",
    "                if container[i][j] != array[j]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void setrow(int[:,:] container, int pos, int[:] array) nogil:\n",
    "    cdef int i\n",
    "    for i in prange(len(container[pos]), schedule='static', num_threads=8):\n",
    "        container[pos][i] = array[i]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int[:,:] allPerms(int[:] source, long long fact):\n",
    "    cdef int i = 0\n",
    "    cdef int k\n",
    "    perm = itertools.permutations(source)\n",
    "    cdef int[:,:] result = np.zeros((fact, len(source)), dtype=int)\n",
    "    for p in perm:\n",
    "        for k in range(len(p)):\n",
    "            result[i][k] = p[k]\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "#source: label -> docid*, i: int, j: int, count: int, perms_with_prob: tuple<int> -> float\n",
    "#return: number of not computed permutations\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def perform_permutation(query, int i, int j, int count, int[:,:] perms, int start):\n",
    "    if not i in query.labels or not j in query.labels:\n",
    "        # no swapping possible\n",
    "        return count, start\n",
    "    # find the indexes of the desired labels\n",
    "    i = [k for k in range(len(query.labels)) if query.labels[k] == i][0]\n",
    "    j = [k for k in range(len(query.labels)) if query.labels[k] == j][0]\n",
    "    cdef int c = 0\n",
    "    cdef int _min = min(len(query.docs[i]), len(query.docs[j]))\n",
    "    cdef int amount = max(1, int(_min * .5))\n",
    "    limit = factorial(_min) / (factorial(amount) * factorial(_min - amount))\n",
    "    cdef int k\n",
    "    cdef int d\n",
    "    for k in range(count):\n",
    "        perm = query.docs.copy()\n",
    "        first = random.sample(range(len(query.docs[i])), k=amount)\n",
    "        second = random.sample(range(len(query.docs[j])), k=amount)\n",
    "        for d in range(len(first)):\n",
    "            perm[i][first[d]], perm[j][second[d]] = query.docs[j][second[d]], query.docs[i][first[d]]\n",
    "        p = np.concatenate(perm)\n",
    "        if not contained(perms, p):\n",
    "            setrow(perms, start + c, p)\n",
    "            c += 1\n",
    "            if c == limit:\n",
    "                return count - c, start + c\n",
    "        else:\n",
    "            k -= 1\n",
    "    return 0, start + c\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def process_query(query, alllabels):\n",
    "    cdef int carry = 0\n",
    "    fact = factorial(len(query.alldocs))\n",
    "    cdef perms\n",
    "    cdef int last = 0\n",
    "    if fact <= RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS:\n",
    "        # evaluate all possible permutations, each one representing a different ranking\n",
    "        perms = allPerms(query.alldocs, fact)\n",
    "    else:\n",
    "        perms = np.negative(np.ones((RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS, len(query.alldocs)), dtype=int))\n",
    "        # switch the labels of the documents, then sort the documents by label to obtain a ranking\n",
    "        carry, last = perform_permutation(query, 4, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[0], perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[1] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[2] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 3, RANK_SAMPLE_SET_DISTRIBUTIONS[3] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[4] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[5] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[6] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[7] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[8] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 1, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[9] + carry, perms, last)\n",
    "        if carry != 0:\n",
    "            if not query.alldocs in perms:\n",
    "                perms[last] = query.alldocs\n",
    "        perms = perms[perms.max(axis=1)>=0]\n",
    "    cdef double[:] probs = np.zeros(len(perms))\n",
    "    cdef double[:] ndcgs = np.zeros(len(perms))\n",
    "    query.setperms(perms)\n",
    "    query.setprobs(rank_probabilities(perms, probs, alllabels))\n",
    "    cdef int k = min(10, len(perms[0]))\n",
    "    for i in range(len(perms)):\n",
    "        ndcgs[i] = ndcg_k(perms[i], alllabels, k, query.idealdcg)\n",
    "    query.setndcgs(ndcgs)\n",
    "    return query\n",
    "\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                           GRADIENTS EVALUATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double[:,:] doc_energy(int[:] rank, double[:] scores, double[:,:] result) nogil:\n",
    "    cdef int m = len(rank)\n",
    "    if m == 1 or m == 0:\n",
    "        return result\n",
    "    cdef double factor = 4.0 / (m * ((m - 1)**2))\n",
    "    cdef double res\n",
    "    cdef double res_w_scores\n",
    "    cdef int k, pos\n",
    "    for pos in prange(len(rank), schedule='static', num_threads=8):\n",
    "        res = 0.0\n",
    "        res_w_scores = 0.0\n",
    "        for k in range(len(rank)):\n",
    "            if k < pos: \n",
    "                res = res + (pos - k)\n",
    "                res_w_scores = res_w_scores + (pos - k) * (scores[rank[pos]] - scores[rank[k]])\n",
    "            #elif k > pos: \n",
    "            #    res = res + (k - pos)\n",
    "            #    res_w_scores = res_w_scores + (k - pos) * (scores[rank[k]] - scores[rank[pos]])\n",
    "        result[rank[pos]][0] = factor * res_w_scores\n",
    "        result[rank[pos]][1] = factor * res\n",
    "        #printf(\"result of %i: m %i, factor %f, res %f, res_scores %f, result[0] %f, result[1] %f\\n\", pos, m, factor, res_w_scores, res, result[rank[pos]][0], result[rank[pos]][0])\n",
    "    return result\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cpdef double[:,:,:] doc_rank_probabilities(int[:,:] sampleSet, double[:,:,:] norm_probs, double[:] scores, double[:,:] accumulator, double[:,:] tmp) nogil:\n",
    "    cdef double norm = 0\n",
    "    cdef double grad_norm = 0\n",
    "    cdef double _energy = 0\n",
    "    cdef double grad_energy = 0\n",
    "    cdef int r\n",
    "    cdef int d\n",
    "    cdef int pos\n",
    "    cdef int doc\n",
    "    \n",
    "    for r in prange(len(sampleSet), schedule='static', num_threads=8):\n",
    "        doc_energy(sampleSet[r], scores, tmp)\n",
    "        for d in range(len(sampleSet[r])):\n",
    "            doc = sampleSet[r][d]\n",
    "            norm_probs[doc][r][0] = exp(-tmp[doc][0]) # e^{-E}\n",
    "            norm_probs[doc][r][1] = -tmp[doc][1] * norm_probs[doc][r][0] # -E' * e^{-E}\n",
    "            accumulator[doc][0] = accumulator[doc][0] + norm_probs[doc][r][0] # sum(e^{-E})\n",
    "            accumulator[doc][1] = accumulator[doc][1] + norm_probs[doc][r][1] # sum(-E' * e^{-E})\n",
    "        \n",
    "        #_energy, grad_energy = doc_energy(sampleSet[r], scores, pos) # E, E'\n",
    "        #norm_probs[r][0] = exp(-_energy) # e^{-E}\n",
    "        #norm_probs[r][1] = -grad_energy * norm_probs[r][0] # -E' * e^{-E}\n",
    "        #norm += norm_probs[r][0] # sum(e^{-E})\n",
    "        #grad_norm += norm_probs[r][1] # sum(-E' * e^{-E})\n",
    "\n",
    "    for pos in prange(len(sampleSet[0]), schedule='static', num_threads=8):\n",
    "        doc = sampleSet[0][pos]\n",
    "        # -E' * e^{-E} * sum(e^{-E}) - e^{-E} * sum(-E' * e^{-E})\n",
    "        # _______________________________________________________\n",
    "        # (sum(e^{-E}))^2\n",
    "        norm_probs[doc][r][1] = ((norm_probs[doc][r][1] * accumulator[doc][0]) - (norm_probs[doc][r][0] * accumulator[doc][1])) / (accumulator[doc][0]**2)\n",
    "        norm_probs[doc][r][0] = norm_probs[doc][r][0] / accumulator[doc][0] # e^{-E} / sum(e^{-E})\n",
    "        \n",
    "    #for r in prange(len(norm_probs), schedule='static', num_threads=8):\n",
    "    #    norm_probs[r][0] = norm_probs[r][0] / norm # e^{-E} / sum(e^{-E})\n",
    "        # -E' * e^{-E} * sum(e^{-E}) - e^{-E} * sum(-E' * e^{-E})\n",
    "        # _______________________________________________________\n",
    "        # (sum(e^{-E}))^2\n",
    "    #    norm_probs[r][1] = ((norm_probs[r][1] * norm) - (norm_probs[r][0] * grad_norm)) / (norm**2) \n",
    "    return norm_probs\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double[:,:] grad_cross_entropy(int[:,:] perms, double[:] probs, double[:,:,:] scores_probs, double[:,:] entropies) nogil:\n",
    "    cdef int i, doc, j\n",
    "    for i in prange(len(perms[0]), schedule='static', num_threads=8):\n",
    "        doc = perms[0][i]\n",
    "        for j in range(len(perms)):\n",
    "            entropies[doc][0] = entropies[doc][0] + -probs[j] * log(scores_probs[doc][j][0])\n",
    "            entropies[doc][1] = entropies[doc][1] + -1 * (probs[j] / scores_probs[doc][j][0]) * scores_probs[doc][j][1]\n",
    "    return entropies\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double[:,:] grad_monte_carlo_gain(int[:,:] perms, double[:,:,:] scores_probs, double[:] scores, double[:] ndcgs, double ideal, double[:,:] gains) nogil:\n",
    "    cdef int i, doc, j\n",
    "    cdef int k = min(10, len(perms[0]))\n",
    "    for i in prange(len(perms[0]), schedule='static', num_threads=8):\n",
    "        doc = perms[0][i]\n",
    "        for j in range(len(perms)):\n",
    "            gains[doc][0] = gains[doc][0] + scores_probs[doc][j][0] * ndcgs[j]#ndcg_k(perms[j], scores, k, ideal)#ndcgs[j]\n",
    "            gains[doc][1] = gains[doc][1] + scores_probs[doc][j][1] * ndcgs[j]#ndcg_k(perms[j], scores, k, ideal)#ndcgs[j]\n",
    "    return gains \n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def eval_boltzrank_grads(queries, preds): \n",
    "    cdef double lam = .9\n",
    "    cdef double[:] gain = np.ones_like(preds)\n",
    "    cdef double[:] hess = np.ones_like(preds) \n",
    "    \n",
    "    cdef int d, i\n",
    "    cdef double[:,:,:] score_probs\n",
    "    cdef double[:,:] accumulator = np.zeros((len(preds), 2), dtype=np.double) \n",
    "    cdef double[:,:] tmp = np.zeros((len(preds), 2), dtype=np.double) \n",
    "    cdef double[:,:] gains = np.zeros((len(preds), 2), dtype=np.double) \n",
    "    cdef double[:,:] entropies = np.zeros((len(preds), 2), dtype=np.double) \n",
    "    for q in queries.values():\n",
    "        score_probs = np.zeros((len(preds), len(q.probs), 2), dtype=np.double)\n",
    "        score_probs = doc_rank_probabilities(q.perms, score_probs, preds, accumulator, tmp)\n",
    "        gains = grad_monte_carlo_gain(q.perms, score_probs, preds, q.ndcgs, q.idealdcg, gains) \n",
    "        entropies = grad_cross_entropy(q.perms, q.probs, score_probs, entropies)\n",
    "    for i in range(len(gain)):\n",
    "        gain[i] = (lam * gains[i][1]) - ((1-lam) * entropies[i][1])\n",
    "    return gain, hess\n",
    "\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                            METRIC EVALUATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double energy(int[:] rank, double[:] scores) nogil:\n",
    "    cdef int m = len(rank)\n",
    "    if m == 1 or m == 0:\n",
    "        return 0\n",
    "    cdef double factor = 4 / (m * ((m - 1)**2))\n",
    "    cdef double res = 0\n",
    "    cdef int j, k\n",
    "    for k in prange(m, schedule='static', num_threads=8):\n",
    "        for j in range(k + 1, m):\n",
    "            res += (j - k) * (scores[rank[j]] - scores[rank[k]])\n",
    "    return factor * res\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cpdef double[:] rank_probabilities(int[:,:] sampleSet, double[:] norm_probs, double[:] scores) nogil:\n",
    "    cdef double norm = 0\n",
    "    cdef int r\n",
    "    for r in prange(len(sampleSet), schedule='static', num_threads=8):\n",
    "        norm_probs[r] = exp(-energy(sampleSet[r], scores))\n",
    "        norm += norm_probs[r]\n",
    "    for r in prange(len(norm_probs), schedule='static', num_threads=8):\n",
    "        norm_probs[r] = norm_probs[r] / norm\n",
    "    return norm_probs\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double cross_entropy(double[:] probs, double[:] scores_probs) nogil:\n",
    "    cdef double result = 0\n",
    "    cdef int i\n",
    "    for i in prange(len(probs), schedule='static', num_threads=8):\n",
    "        result += probs[i] * log(scores_probs[i])\n",
    "    return -result\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double monte_carlo_gain(int[:,:] perms, double[:] scores_probs, double[:] ndcgs) nogil:\n",
    "    cdef double result = 0\n",
    "    cdef int i\n",
    "    cdef int k = min(10, len(perms[0]))\n",
    "    for i in prange(len(perms), schedule='static', num_threads=8):\n",
    "        result += scores_probs[i] * ndcgs[i]\n",
    "    return result\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def eval_boltzrank(queries, preds):\n",
    "    cdef double lam = .9\n",
    "    cdef double[:] score_probs\n",
    "    cdef double mc = 0\n",
    "    cdef double ce = 0\n",
    "    cdef double _mc, _ce\n",
    "    for q in queries.values():\n",
    "        score_probs = np.zeros(len(q.probs), dtype=np.double)\n",
    "        score_probs = rank_probabilities(q.perms, score_probs, preds)\n",
    "        mc += monte_carlo_gain(q.perms, score_probs, q.ndcgs) \n",
    "        ce += cross_entropy(q.probs, score_probs)\n",
    "    return (lam * mc) - ((1-lam) * ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/train.txt\n",
      "validation file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/vali.txt\n",
      "test file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/test.txt\n",
      "loading datasets... \n",
      "train dataset loading took 48.109375 s\n",
      "validation dataset loading took 15.96875 s\n",
      "test dataset loading took 16.15625 s\n",
      "converting datasets to LightGBM format... \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_file, valid_file, test_file = retrieveFileNames()\n",
    "\n",
    "print(\"training file: \" + train_file)\n",
    "print(\"validation file: \" + valid_file)\n",
    "print(\"test file: \" + test_file)\n",
    "    \n",
    "print(\"loading datasets... \")\n",
    "import time\n",
    "start = time.process_time()\n",
    "train_dataset = loadDataset(train_file)\n",
    "print(\"train dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "valid_dataset = loadDataset(valid_file)\n",
    "print(\"validation dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "test_dataset = loadDataset(test_file)\n",
    "print(\"test dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "\n",
    "import itertools\n",
    "print(\"converting datasets to LightGBM format... \")\n",
    "train_lgb = loadLightGBM(train_dataset)\n",
    "valid_lgb = loadLightGBM(valid_dataset)\n",
    "test_lgb = loadLightGBM(test_dataset)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating query-documents mappings...\n",
      "done\n",
      "creating sample sets...\n",
      "sample set creation took 49.671875 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "print(\"creating query-documents mappings...\")\n",
    "train_id = file_len(train_file)\n",
    "vali_id = file_len(valid_file)\n",
    "test_id = file_len(test_file)\n",
    "ds_to_queries = {}\n",
    "ds_to_queries[train_id] = mapQueryToDocuments(train_dataset)\n",
    "ds_to_queries[vali_id] = mapQueryToDocuments(valid_dataset)\n",
    "ds_to_queries[test_id] = mapQueryToDocuments(test_dataset)\n",
    "#queries, alllabels = mapQueryToDocuments(train_dataset)\n",
    "print(\"done\")\n",
    "\n",
    "print(\"creating sample sets...\")\n",
    "start = time.process_time()\n",
    "for ds_id, queries in ds_to_queries.items():\n",
    "    for q in queries[0].values():\n",
    "        process_query(q, queries[1])\n",
    "#for q in queries.values():\n",
    "#    queries[q.qid] = process_query(q, alllabels)\n",
    "print(\"sample set creation took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training lightgbm...\n",
      "min -6.0162037037037015 max 0.0 mean -0.1418882286772303 std 0.1404908177113355\n",
      "preds [0. 0. 0. ... 0. 0. 0.]\n",
      "gain [-0.12558961 -0.32269656 -0.19549435 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[1]\ttrain's BoltzRank-NDCG@10: -643.079\tvalid's BoltzRank-NDCG@10: -211.435\ttest's BoltzRank-NDCG@10: -199.716\n",
      "min -6.017686442072677 max 0.0 mean -0.14188828783508078 std 0.14049043736824568\n",
      "preds [0.01567009 0.01262205 0.01262205 ... 0.02362018 0.02362018 0.02362018]\n",
      "gain [-0.1255873  -0.3226975  -0.19549481 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[2]\ttrain's BoltzRank-NDCG@10: -643.069\tvalid's BoltzRank-NDCG@10: -211.432\ttest's BoltzRank-NDCG@10: -199.713\n",
      "min -6.019169904115585 max 0.0 mean -0.14188835679296147 std 0.14049036026448097\n",
      "preds [0.03134019 0.02524416 0.02524416 ... 0.04723736 0.04723736 0.04723736]\n",
      "gain [-0.125585   -0.32269844 -0.19549527 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[3]\ttrain's BoltzRank-NDCG@10: -643.06\tvalid's BoltzRank-NDCG@10: -211.428\ttest's BoltzRank-NDCG@10: -199.711\n",
      "min -6.020654091752432 max 0.0 mean -0.14188843546357222 std 0.1404905827472575\n",
      "preds [0.04701031 0.03786633 0.03786633 ... 0.07085158 0.07085158 0.07085158]\n",
      "gain [-0.12558269 -0.32269939 -0.19549573 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[4]\ttrain's BoltzRank-NDCG@10: -643.052\tvalid's BoltzRank-NDCG@10: -211.425\ttest's BoltzRank-NDCG@10: -199.709\n",
      "min -6.029907971021731 max 0.0 mean -0.14188852376483863 std 0.14049110170966658\n",
      "preds [0.06268045 0.05048855 0.05048855 ... 0.09446287 0.09446287 0.09446287]\n",
      "gain [-0.12558038 -0.32270033 -0.1954962  ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[5]\ttrain's BoltzRank-NDCG@10: -643.044\tvalid's BoltzRank-NDCG@10: -211.421\ttest's BoltzRank-NDCG@10: -199.707\n",
      "min -6.057656679918918 max 0.0 mean -0.14188862161983584 std 0.14049191457902746\n",
      "preds [0.07835061 0.06311084 0.06311084 ... 0.11807126 0.11807126 0.11807126]\n",
      "gain [-0.12557807 -0.32270127 -0.19549666 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[6]\ttrain's BoltzRank-NDCG@10: -643.036\tvalid's BoltzRank-NDCG@10: -211.418\ttest's BoltzRank-NDCG@10: -199.706\n",
      "min -6.085552827778009 max 0.0 mean -0.14188872895671584 std 0.14049301930654354\n",
      "preds [0.09402078 0.07573319 0.07573319 ... 0.14167678 0.14167678 0.14167678]\n",
      "gain [-0.12557576 -0.32270221 -0.19549712 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[7]\ttrain's BoltzRank-NDCG@10: -643.028\tvalid's BoltzRank-NDCG@10: -211.415\ttest's BoltzRank-NDCG@10: -199.704\n",
      "min -6.1135972790895 max 0.0 mean -0.14188884570863997 std 0.14049441435823054\n",
      "preds [0.10969097 0.08835559 0.08835559 ... 0.16527946 0.16527946 0.16527946]\n",
      "gain [-0.12557346 -0.32270315 -0.19549758 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[8]\ttrain's BoltzRank-NDCG@10: -643.021\tvalid's BoltzRank-NDCG@10: -211.411\ttest's BoltzRank-NDCG@10: -199.703\n",
      "min -6.14179090222799 max 0.0 mean -0.1418889718137143 std 0.14049609870708482\n",
      "preds [0.12536118 0.10097805 0.10097805 ... 0.18887933 0.18887933 0.18887933]\n",
      "gain [-0.12557115 -0.3227041  -0.19549804 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[9]\ttrain's BoltzRank-NDCG@10: -643.014\tvalid's BoltzRank-NDCG@10: -211.408\ttest's BoltzRank-NDCG@10: -199.702\n",
      "min -6.170134569538811 max 0.0 mean -0.1418891072149297 std 0.140498071826479\n",
      "preds [0.14103141 0.11360058 0.11360058 ... 0.21247642 0.21247642 0.21247642]\n",
      "gain [-0.12556884 -0.32270504 -0.19549851 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[10]\ttrain's BoltzRank-NDCG@10: -643.008\tvalid's BoltzRank-NDCG@10: -211.404\ttest's BoltzRank-NDCG@10: -199.701\n",
      "min -6.198629157193071 max 0.0 mean -0.14188925186010426 std 0.14050033368474285\n",
      "preds [0.15670166 0.12622316 0.12622316 ... 0.23607075 0.23607075 0.23607075]\n",
      "gain [-0.12556653 -0.32270598 -0.19549897 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[11]\ttrain's BoltzRank-NDCG@10: -643.001\tvalid's BoltzRank-NDCG@10: -211.401\ttest's BoltzRank-NDCG@10: -199.7\n",
      "min -6.227275545307476 max 0.0 mean -0.14188940570183053 std 0.14050288474095077\n",
      "preds [0.17237192 0.1388458  0.1388458  ... 0.25966236 0.25966236 0.25966236]\n",
      "gain [-0.12556423 -0.32270692 -0.19549943 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[12]\ttrain's BoltzRank-NDCG@10: -642.996\tvalid's BoltzRank-NDCG@10: -211.398\ttest's BoltzRank-NDCG@10: -199.699\n",
      "min -6.25607461793068 max 0.0 mean -0.14188956869742517 std 0.14050572594188593\n",
      "preds [0.1880422  0.1514685  0.1514685  ... 0.28325126 0.28325126 0.28325126]\n",
      "gain [-0.12556192 -0.32270786 -0.19549989 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[13]\ttrain's BoltzRank-NDCG@10: -642.99\tvalid's BoltzRank-NDCG@10: -211.395\ttest's BoltzRank-NDCG@10: -199.698\n",
      "min -6.285027263105638 max 0.0 mean -0.14188974080888456 std 0.14050885872019392\n",
      "preds [0.2037125  0.16409126 0.16409126 ... 0.30683749 0.30683749 0.30683749]\n",
      "gain [-0.12555961 -0.32270881 -0.19550036 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[14]\ttrain's BoltzRank-NDCG@10: -642.985\tvalid's BoltzRank-NDCG@10: -211.391\ttest's BoltzRank-NDCG@10: -199.698\n",
      "min -6.31413437272502 max 0.0 mean -0.14188992200284026 std 0.1405122849936695\n",
      "preds [0.21938281 0.17671408 0.17671408 ... 0.33042107 0.33042107 0.33042107]\n",
      "gain [-0.12555731 -0.32270975 -0.19550082 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[15]\ttrain's BoltzRank-NDCG@10: -642.98\tvalid's BoltzRank-NDCG@10: -211.388\ttest's BoltzRank-NDCG@10: -199.697\n",
      "min -6.3572231134043955 max 0.0 mean -0.14189011225052142 std 0.14051600716578538\n",
      "preds [0.23505315 0.18933695 0.18933695 ... 0.35400202 0.35400202 0.35400202]\n",
      "gain [-0.125555   -0.32271069 -0.19550128 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[16]\ttrain's BoltzRank-NDCG@10: -642.975\tvalid's BoltzRank-NDCG@10: -211.385\ttest's BoltzRank-NDCG@10: -199.697\n",
      "min -6.401771512066149 max 0.0 mean -0.14189031152771828 std 0.14052002812735123\n",
      "preds [0.2507235  0.20195989 0.20195989 ... 0.37758037 0.37758037 0.37758037]\n",
      "gain [-0.12555269 -0.32271163 -0.19550174 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[17]\ttrain's BoltzRank-NDCG@10: -642.971\tvalid's BoltzRank-NDCG@10: -211.382\ttest's BoltzRank-NDCG@10: -199.697\n",
      "min -6.446666169697446 max 0.0 mean -0.14189051981475043 std 0.1405243512594084\n",
      "preds [0.26639386 0.21458288 0.21458288 ... 0.40115614 0.40115614 0.40115614]\n",
      "gain [-0.12555038 -0.32271257 -0.19550221 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[18]\ttrain's BoltzRank-NDCG@10: -642.967\tvalid's BoltzRank-NDCG@10: -211.378\ttest's BoltzRank-NDCG@10: -199.697\n",
      "min -6.491909890065785 max 0.0 mean -0.14189073709643654 std 0.1405289804372946\n",
      "preds [0.28206425 0.22720594 0.22720594 ... 0.42472935 0.42472935 0.42472935]\n",
      "gain [-0.12554808 -0.32271352 -0.19550267 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[19]\ttrain's BoltzRank-NDCG@10: -642.963\tvalid's BoltzRank-NDCG@10: -211.375\ttest's BoltzRank-NDCG@10: -199.697\n",
      "min -6.537505497693597 max 0.0 mean -0.14189096336206905 std 0.14053392003596682\n",
      "preds [0.29773465 0.23982905 0.23982905 ... 0.44830003 0.44830003 0.44830003]\n",
      "gain [-0.12554577 -0.32271446 -0.19550313 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[20]\ttrain's BoltzRank-NDCG@10: -642.96\tvalid's BoltzRank-NDCG@10: -211.372\ttest's BoltzRank-NDCG@10: -199.697\n",
      "min -6.583455837945446 max 0.0 mean -0.14189119860539096 std 0.14053917493656343\n",
      "preds [0.31340508 0.25245222 0.25245222 ... 0.4718682  0.4718682  0.4718682 ]\n",
      "gain [-0.12554346 -0.3227154  -0.19550359 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[21]\ttrain's BoltzRank-NDCG@10: -642.956\tvalid's BoltzRank-NDCG@10: -211.369\ttest's BoltzRank-NDCG@10: -199.697\n",
      "min -6.629763777129683 max 0.0 mean -0.14189144282457797 std 0.14054475053424112\n",
      "preds [0.32907551 0.26507546 0.26507546 ... 0.49543389 0.49543389 0.49543389]\n",
      "gain [-0.12554116 -0.32271634 -0.19550405 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[22]\ttrain's BoltzRank-NDCG@10: -642.953\tvalid's BoltzRank-NDCG@10: -211.366\ttest's BoltzRank-NDCG@10: -199.698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min -6.67643220277686 max 0.0 mean -0.14189169602222138 std 0.14055065274732392\n",
      "preds [0.34474597 0.27769875 0.27769875 ... 0.5189971  0.5189971  0.5189971 ]\n",
      "gain [-0.12553885 -0.32271728 -0.19550452 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[23]\ttrain's BoltzRank-NDCG@10: -642.951\tvalid's BoltzRank-NDCG@10: -211.362\ttest's BoltzRank-NDCG@10: -199.698\n",
      "min -6.723464023455339 max 0.0 mean -0.1418919582053133 std 0.14055688802772776\n",
      "preds [0.36041645 0.2903221  0.2903221  ... 0.54255786 0.54255786 0.54255786]\n",
      "gain [-0.12553654 -0.32271823 -0.19550498 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[24]\ttrain's BoltzRank-NDCG@10: -642.948\tvalid's BoltzRank-NDCG@10: -211.359\ttest's BoltzRank-NDCG@10: -199.699\n",
      "min -6.770862169029777 max 0.0 mean -0.14189222938523838 std 0.1405634633728133\n",
      "preds [0.37608694 0.30294551 0.30294551 ... 0.5661162  0.5661162  0.5661162 ]\n",
      "gain [-0.12553424 -0.32271917 -0.19550544 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[25]\ttrain's BoltzRank-NDCG@10: -642.946\tvalid's BoltzRank-NDCG@10: -211.356\ttest's BoltzRank-NDCG@10: -199.7\n",
      "min -6.818629590992151 max 0.0 mean -0.14189250957776725 std 0.1405703863386584\n",
      "preds [0.39175745 0.31556897 0.31556897 ... 0.58967212 0.58967212 0.58967212]\n",
      "gain [-0.12553193 -0.32272011 -0.1955059  ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[26]\ttrain's BoltzRank-NDCG@10: -642.944\tvalid's BoltzRank-NDCG@10: -211.353\ttest's BoltzRank-NDCG@10: -199.7\n",
      "min -6.866769262222845 max 0.0 mean -0.1418927988030511 std 0.14057766505467967\n",
      "preds [0.40742797 0.3281925  0.3281925  ... 0.61322566 0.61322566 0.61322566]\n",
      "gain [-0.12552962 -0.32272105 -0.19550637 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[27]\ttrain's BoltzRank-NDCG@10: -642.943\tvalid's BoltzRank-NDCG@10: -211.35\ttest's BoltzRank-NDCG@10: -199.701\n",
      "min -6.915284177164677 max 0.0 mean -0.14189309708562 std 0.14058530823980078\n",
      "preds [0.42309852 0.34081609 0.34081609 ... 0.63677683 0.63677683 0.63677683]\n",
      "gain [-0.12552732 -0.32272199 -0.19550683 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[28]\ttrain's BoltzRank-NDCG@10: -642.941\tvalid's BoltzRank-NDCG@10: -211.347\ttest's BoltzRank-NDCG@10: -199.702\n",
      "min -6.964177352182658 max 0.0 mean -0.14189340445438892 std 0.14059332522022058\n",
      "preds [0.43876908 0.35343973 0.35343973 ... 0.66032564 0.66032564 0.66032564]\n",
      "gain [-0.12552501 -0.32272294 -0.19550729 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[29]\ttrain's BoltzRank-NDCG@10: -642.94\tvalid's BoltzRank-NDCG@10: -211.344\ttest's BoltzRank-NDCG@10: -199.704\n",
      "min -7.013451825401618 max 0.0 mean -0.1418937209426577 std 0.14060172594863218\n",
      "preds [0.45443966 0.36606344 0.36606344 ... 0.68387212 0.68387212 0.68387212]\n",
      "gain [-0.12552271 -0.32272388 -0.19550775 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[30]\ttrain's BoltzRank-NDCG@10: -642.939\tvalid's BoltzRank-NDCG@10: -211.341\ttest's BoltzRank-NDCG@10: -199.705\n",
      "min -7.063110656955873 max 0.0 mean -0.14189404658812313 std 0.14061052102520627\n",
      "preds [0.47011026 0.3786872  0.3786872  ... 0.70741628 0.70741628 0.70741628]\n",
      "gain [-0.1255204  -0.32272482 -0.19550821 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[31]\ttrain's BoltzRank-NDCG@10: -642.938\tvalid's BoltzRank-NDCG@10: -211.338\ttest's BoltzRank-NDCG@10: -199.706\n",
      "min -7.113156929034284 max 0.0 mean -0.14189438143288813 std 0.1406197217202037\n",
      "preds [0.48578087 0.39131102 0.39131102 ... 0.73095814 0.73095814 0.73095814]\n",
      "gain [-0.12551809 -0.32272576 -0.19550868 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[32]\ttrain's BoltzRank-NDCG@10: -642.938\tvalid's BoltzRank-NDCG@10: -211.335\ttest's BoltzRank-NDCG@10: -199.707\n",
      "min -7.163593746036733 max 0.0 mean -0.14189472552347693 std 0.14062933999839541\n",
      "preds [0.50145151 0.4039349  0.4039349  ... 0.75449772 0.75449772 0.75449772]\n",
      "gain [-0.12551579 -0.3227267  -0.19550914 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[33]\ttrain's BoltzRank-NDCG@10: -642.937\tvalid's BoltzRank-NDCG@10: -211.332\ttest's BoltzRank-NDCG@10: -199.709\n",
      "min -7.214424234646729 max 0.0 mean -0.1418950789108513 std 0.1406393885452832\n",
      "preds [0.51712216 0.41655884 0.41655884 ... 0.77803503 0.77803503 0.77803503]\n",
      "gain [-0.12551348 -0.32272765 -0.1955096  ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[34]\ttrain's BoltzRank-NDCG@10: -642.937\tvalid's BoltzRank-NDCG@10: -211.329\ttest's BoltzRank-NDCG@10: -199.711\n",
      "min -7.265651543849078 max 0.0 mean -0.14189544165042978 std 0.1406498807952049\n",
      "preds [0.53279283 0.42918284 0.42918284 ... 0.80157009 0.80157009 0.80157009]\n",
      "gain [-0.12551118 -0.32272859 -0.19551006 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[35]\ttrain's BoltzRank-NDCG@10: -642.937\tvalid's BoltzRank-NDCG@10: -211.326\ttest's BoltzRank-NDCG@10: -199.712\n",
      "min -7.317278845243141 max 0.0 mean -0.1418958138021134 std 0.14066083096150359\n",
      "preds [0.54846351 0.4418069  0.4418069  ... 0.8251029  0.8251029  0.8251029 ]\n",
      "gain [-0.12550887 -0.32272953 -0.19551052 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[36]\ttrain's BoltzRank-NDCG@10: -642.937\tvalid's BoltzRank-NDCG@10: -211.323\ttest's BoltzRank-NDCG@10: -199.714\n",
      "min -7.369309332911685 max 0.0 mean -0.14189619543030896 std 0.14067225406861755\n",
      "preds [0.56413422 0.45443102 0.45443102 ... 0.8486335  0.8486335  0.8486335 ]\n",
      "gain [-0.12550657 -0.32273047 -0.19551099 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[37]\ttrain's BoltzRank-NDCG@10: -642.938\tvalid's BoltzRank-NDCG@10: -211.321\ttest's BoltzRank-NDCG@10: -199.716\n",
      "min -7.4217462237208744 max 0.0 mean -0.1418965866039591 std 0.1406841659864214\n",
      "preds [0.57980494 0.46705519 0.46705519 ... 0.87216189 0.87216189 0.87216189]\n",
      "gain [-0.12550426 -0.32273141 -0.19551145 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[38]\ttrain's BoltzRank-NDCG@10: -642.938\tvalid's BoltzRank-NDCG@10: -211.318\ttest's BoltzRank-NDCG@10: -199.717\n",
      "min -7.474592757228725 max 0.0 mean -0.14189698739657403 std 0.14069658346670727\n",
      "preds [0.59547568 0.47967943 0.47967943 ... 0.89568809 0.89568809 0.89568809]\n",
      "gain [-0.12550196 -0.32273235 -0.19551191 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[39]\ttrain's BoltzRank-NDCG@10: -642.939\tvalid's BoltzRank-NDCG@10: -211.315\ttest's BoltzRank-NDCG@10: -199.719\n",
      "min -7.527852195956531 max 0.0 mean -0.14189739788626776 std 0.14070952418205418\n",
      "preds [0.61114643 0.49230373 0.49230373 ... 0.91921211 0.91921211 0.91921211]\n",
      "gain [-0.12549965 -0.3227333  -0.19551237 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[40]\ttrain's BoltzRank-NDCG@10: -642.94\tvalid's BoltzRank-NDCG@10: -211.312\ttest's BoltzRank-NDCG@10: -199.721\n",
      "min -7.581527825319377 max 0.0 mean -0.1418978181557931 std 0.1407230067670208\n",
      "preds [0.62681721 0.50492808 0.50492808 ... 0.94273397 0.94273397 0.94273397]\n",
      "gain [-0.12549735 -0.32273424 -0.19551284 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[41]\ttrain's BoltzRank-NDCG@10: -642.941\tvalid's BoltzRank-NDCG@10: -211.309\ttest's BoltzRank-NDCG@10: -199.723\n",
      "min -7.635622953790792 max 0.0 mean -0.1418982482925843 std 0.1407370508619253\n",
      "preds [0.642488   0.51755249 0.51755249 ... 0.96625367 0.96625367 0.96625367]\n",
      "gain [-0.12549504 -0.32273518 -0.1955133  ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[42]\ttrain's BoltzRank-NDCG@10: -642.943\tvalid's BoltzRank-NDCG@10: -211.306\ttest's BoltzRank-NDCG@10: -199.725\n",
      "min -7.690140913039001 max 0.0 mean -0.1418986883888014 std 0.14075167715923448\n",
      "preds [0.65815881 0.53017696 0.53017696 ... 0.98977124 0.98977124 0.98977124]\n",
      "gain [-0.12549274 -0.32273612 -0.19551376 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[43]\ttrain's BoltzRank-NDCG@10: -642.944\tvalid's BoltzRank-NDCG@10: -211.304\ttest's BoltzRank-NDCG@10: -199.728\n",
      "min -7.745085058023373 max 0.0 mean -0.14189913854137765 std 0.14076690745269002\n",
      "preds [0.67382964 0.5428015  0.5428015  ... 1.01328668 1.01328668 1.01328668]\n",
      "gain [-0.12549043 -0.32273706 -0.19551422 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[44]\ttrain's BoltzRank-NDCG@10: -642.946\tvalid's BoltzRank-NDCG@10: -211.301\ttest's BoltzRank-NDCG@10: -199.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min -7.800458766806487 max 0.0 mean -0.14189959885206574 std 0.14078276468917597\n",
      "preds [0.68950048 0.55542609 0.55542609 ... 1.0368     1.0368     1.0368    ]\n",
      "gain [-0.12548813 -0.32273801 -0.19551468 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[45]\ttrain's BoltzRank-NDCG@10: -642.947\tvalid's BoltzRank-NDCG@10: -211.298\ttest's BoltzRank-NDCG@10: -199.732\n",
      "min -7.856265441098298 max 0.0 mean -0.14190006942749633 std 0.14079927302381798\n",
      "preds [0.70517134 0.56805074 0.56805074 ... 1.06031123 1.06031123 1.06031123]\n",
      "gain [-0.12548582 -0.32273895 -0.19551515 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[46]\ttrain's BoltzRank-NDCG@10: -642.949\tvalid's BoltzRank-NDCG@10: -211.295\ttest's BoltzRank-NDCG@10: -199.734\n",
      "min -7.912508505928778 max 0.0 mean -0.14190055037922988 std 0.14081645787789734\n",
      "preds [0.72084222 0.58067544 0.58067544 ... 1.08382036 1.08382036 1.08382036]\n",
      "gain [-0.12548352 -0.32273989 -0.19551561 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[47]\ttrain's BoltzRank-NDCG@10: -642.951\tvalid's BoltzRank-NDCG@10: -211.293\ttest's BoltzRank-NDCG@10: -199.737\n",
      "min -7.9691914098662116 max 0.0 mean -0.1419010418238163 std 0.14083434600020062\n",
      "preds [0.73651312 0.59330021 0.59330021 ... 1.10732742 1.10732742 1.10732742]\n",
      "gain [-0.12548121 -0.32274083 -0.19551607 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[48]\ttrain's BoltzRank-NDCG@10: -642.953\tvalid's BoltzRank-NDCG@10: -211.29\ttest's BoltzRank-NDCG@10: -199.739\n",
      "min -8.02631762529826 max 0.0 mean -0.14190154388286172 std 0.14085296553180512\n",
      "preds [0.75218404 0.60592504 0.60592504 ... 1.13083241 1.13083241 1.13083241]\n",
      "gain [-0.12547891 -0.32274177 -0.19551653 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[49]\ttrain's BoltzRank-NDCG@10: -642.956\tvalid's BoltzRank-NDCG@10: -211.287\ttest's BoltzRank-NDCG@10: -199.742\n",
      "min -8.083890648102066 max 0.0 mean -0.14190205668308734 std 0.14087234607414542\n",
      "preds [0.76785497 0.61854992 0.61854992 ... 1.15433535 1.15433535 1.15433535]\n",
      "gain [-0.1254766  -0.32274271 -0.19551699 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[50]\ttrain's BoltzRank-NDCG@10: -642.958\tvalid's BoltzRank-NDCG@10: -211.285\ttest's BoltzRank-NDCG@10: -199.744\n",
      "min -8.141913997996937 max 0.0 mean -0.14190258035640255 std 0.1408925187610852\n",
      "preds [0.78352592 0.63117487 0.63117487 ... 1.17783624 1.17783624 1.17783624]\n",
      "gain [-0.1254743  -0.32274366 -0.19551746 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[51]\ttrain's BoltzRank-NDCG@10: -642.96\tvalid's BoltzRank-NDCG@10: -211.282\ttest's BoltzRank-NDCG@10: -199.747\n",
      "min -8.200391218496188 max 0.0 mean -0.14190311503997452 std 0.14091351633467103\n",
      "preds [0.79919689 0.64379987 0.64379987 ... 1.2013351  1.2013351  1.2013351 ]\n",
      "gain [-0.12547199 -0.3227446  -0.19551792 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[52]\ttrain's BoltzRank-NDCG@10: -642.963\tvalid's BoltzRank-NDCG@10: -211.279\ttest's BoltzRank-NDCG@10: -199.749\n",
      "min -8.259325876954454 max 0.0 mean -0.14190366087630438 std 0.14093537322499228\n",
      "preds [0.81486788 0.65642494 0.65642494 ... 1.22483194 1.22483194 1.22483194]\n",
      "gain [-0.12546969 -0.32274554 -0.19551838 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[53]\ttrain's BoltzRank-NDCG@10: -642.966\tvalid's BoltzRank-NDCG@10: -211.277\ttest's BoltzRank-NDCG@10: -199.752\n",
      "min -8.31872156484542 max 0.0 mean -0.14190421801330722 std 0.1409581256343642\n",
      "preds [0.83053888 0.66905006 0.66905006 ... 1.24832676 1.24832676 1.24832676]\n",
      "gain [-0.12546739 -0.32274648 -0.19551884 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[54]\ttrain's BoltzRank-NDCG@10: -642.969\tvalid's BoltzRank-NDCG@10: -211.274\ttest's BoltzRank-NDCG@10: -199.754\n",
      "min -8.378581897412055 max 0.0 mean -0.14190478660438968 std 0.14098181162566847\n",
      "preds [0.8462099  0.68167524 0.68167524 ... 1.27181958 1.27181958 1.27181958]\n",
      "gain [-0.12546508 -0.32274742 -0.1955193  ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[55]\ttrain's BoltzRank-NDCG@10: -642.972\tvalid's BoltzRank-NDCG@10: -211.271\ttest's BoltzRank-NDCG@10: -199.757\n",
      "min -8.438910513954184 max 0.0 mean -0.14190536680853566 std 0.141006471215553\n",
      "preds [0.86188094 0.69430048 0.69430048 ... 1.2953104  1.2953104  1.2953104 ]\n",
      "gain [-0.12546278 -0.32274836 -0.19551977 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[56]\ttrain's BoltzRank-NDCG@10: -642.975\tvalid's BoltzRank-NDCG@10: -211.269\ttest's BoltzRank-NDCG@10: -199.76\n",
      "min -8.499711078014471 max 0.0 mean -0.1419059587903999 std 0.14103214647250115\n",
      "preds [0.877552   0.70692578 0.70692578 ... 1.31879924 1.31879924 1.31879924]\n",
      "gain [-0.12546047 -0.32274931 -0.19552023 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[57]\ttrain's BoltzRank-NDCG@10: -642.978\tvalid's BoltzRank-NDCG@10: -211.266\ttest's BoltzRank-NDCG@10: -199.763\n",
      "min -8.56098727709303 max 0.0 mean -0.1419065627203927 std 0.14105888161965735\n",
      "preds [0.89322307 0.71955114 0.71955114 ... 1.3422861  1.3422861  1.3422861 ]\n",
      "gain [-0.12545817 -0.32275025 -0.19552069 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[58]\ttrain's BoltzRank-NDCG@10: -642.981\tvalid's BoltzRank-NDCG@10: -211.264\ttest's BoltzRank-NDCG@10: -199.765\n",
      "min -8.622742822912251 max 0.0 mean -0.14190717877477918 std 0.14108672314323406\n",
      "preds [0.90889416 0.73217655 0.73217655 ... 1.365771   1.365771   1.365771  ]\n",
      "gain [-0.12545587 -0.32275119 -0.19552115 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[59]\ttrain's BoltzRank-NDCG@10: -642.985\tvalid's BoltzRank-NDCG@10: -211.261\ttest's BoltzRank-NDCG@10: -199.768\n",
      "min -8.684981451288353 max 0.0 mean -0.14190780713577497 std 0.14111571990621777\n",
      "preds [0.92456527 0.74480203 0.74480203 ... 1.38925394 1.38925394 1.38925394]\n",
      "gain [-0.12545356 -0.32275213 -0.19552162 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[60]\ttrain's BoltzRank-NDCG@10: -642.988\tvalid's BoltzRank-NDCG@10: -211.259\ttest's BoltzRank-NDCG@10: -199.771\n",
      "min -8.747706922322488 max 0.0 mean -0.1419084479916507 std 0.14114592326802858\n",
      "preds [0.9402364  0.75742757 0.75742757 ... 1.41273493 1.41273493 1.41273493]\n",
      "gain [-0.12545126 -0.32275307 -0.19552208 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[61]\ttrain's BoltzRank-NDCG@10: -642.992\tvalid's BoltzRank-NDCG@10: -211.256\ttest's BoltzRank-NDCG@10: -199.774\n",
      "min -8.81092302023527 max 0.0 mean -0.1419091015368368 std 0.14117738721001807\n",
      "preds [0.95590755 0.77005316 0.77005316 ... 1.43621398 1.43621398 1.43621398]\n",
      "gain [-0.12544895 -0.32275401 -0.19552254 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[62]\ttrain's BoltzRank-NDCG@10: -642.996\tvalid's BoltzRank-NDCG@10: -211.254\ttest's BoltzRank-NDCG@10: -199.777\n",
      "min -9.052749260834338 max 0.0 mean -0.1419097679720335 std 0.1412101684674559\n",
      "preds [0.97157871 0.78267881 0.78267881 ... 1.4596911  1.4596911  1.4596911 ]\n",
      "gain [-0.12544665 -0.32275496 -0.195523   ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[63]\ttrain's BoltzRank-NDCG@10: -642.999\tvalid's BoltzRank-NDCG@10: -211.251\ttest's BoltzRank-NDCG@10: -199.78\n",
      "min -9.303523802721967 max 0.0 mean -0.1419104475043206 std 0.14124432666782313\n",
      "preds [0.98724989 0.79530453 0.79530453 ... 1.48316629 1.48316629 1.48316629]\n",
      "gain [-0.12544435 -0.3227559  -0.19552346 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[64]\ttrain's BoltzRank-NDCG@10: -643.003\tvalid's BoltzRank-NDCG@10: -211.249\ttest's BoltzRank-NDCG@10: -199.783\n",
      "min -9.5607654010706 max 0.0 mean -0.14191114034727775 std 0.14127992447627777\n",
      "preds [1.00292109 0.8079303  0.8079303  ... 1.50663957 1.50663957 1.50663957]\n",
      "gain [-0.12544204 -0.32275684 -0.19552393 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[65]\ttrain's BoltzRank-NDCG@10: -643.007\tvalid's BoltzRank-NDCG@10: -211.246\ttest's BoltzRank-NDCG@10: -199.786\n",
      "min -9.824641001008384 max 0.0 mean -0.14191184672110227 std 0.14131702774806307\n",
      "preds [1.0185923  0.82055613 0.82055613 ... 1.53011093 1.53011093 1.53011093]\n",
      "gain [-0.12543974 -0.32275778 -0.19552439 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[66]\ttrain's BoltzRank-NDCG@10: -643.011\tvalid's BoltzRank-NDCG@10: -211.244\ttest's BoltzRank-NDCG@10: -199.789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min -10.095321944544894 max 0.0 mean -0.14191256685273368 std 0.141355705688442\n",
      "preds [1.03426354 0.83318202 0.83318202 ... 1.5535804  1.5535804  1.5535804 ]\n",
      "gain [-0.12543744 -0.32275872 -0.19552485 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[67]\ttrain's BoltzRank-NDCG@10: -643.015\tvalid's BoltzRank-NDCG@10: -211.242\ttest's BoltzRank-NDCG@10: -199.792\n",
      "min -10.372984075462824 max 0.0 mean -0.141913300975981 std 0.1413960310205197\n",
      "preds [1.04993479 0.84580797 0.84580797 ... 1.57704797 1.57704797 1.57704797]\n",
      "gain [-0.12543514 -0.32275966 -0.19552531 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[68]\ttrain's BoltzRank-NDCG@10: -643.02\tvalid's BoltzRank-NDCG@10: -211.239\ttest's BoltzRank-NDCG@10: -199.795\n",
      "min -10.657807846747993 max 0.0 mean -0.1419140493316585 std 0.14143808016126827\n",
      "preds [1.06560606 0.85843398 0.85843398 ... 1.60051366 1.60051366 1.60051366]\n",
      "gain [-0.12543283 -0.3227606  -0.19552577 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[69]\ttrain's BoltzRank-NDCG@10: -643.024\tvalid's BoltzRank-NDCG@10: -211.237\ttest's BoltzRank-NDCG@10: -199.798\n",
      "min -10.949978428523567 max 0.0 mean -0.1419148121677154 std 0.14148193340571147\n",
      "preds [1.08127734 0.87106004 0.87106004 ... 1.62397747 1.62397747 1.62397747]\n",
      "gain [-0.12543053 -0.32276155 -0.19552624 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[70]\ttrain's BoltzRank-NDCG@10: -643.028\tvalid's BoltzRank-NDCG@10: -211.235\ttest's BoltzRank-NDCG@10: -199.801\n",
      "min -11.249685820923187 max 0.0 mean -0.14191558973938037 std 0.14152767512039618\n",
      "preds [1.09694865 0.88368617 0.88368617 ... 1.6474394  1.6474394  1.6474394 ]\n",
      "gain [-0.12542823 -0.32276249 -0.1955267  ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[71]\ttrain's BoltzRank-NDCG@10: -643.033\tvalid's BoltzRank-NDCG@10: -211.232\ttest's BoltzRank-NDCG@10: -199.804\n",
      "min -11.557124967173374 max 0.0 mean -0.14191638230930004 std 0.1415753939456771\n",
      "preds [1.11261997 0.89631236 0.89631236 ... 1.67089947 1.67089947 1.67089947]\n",
      "gain [-0.12542592 -0.32276343 -0.19552716 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[72]\ttrain's BoltzRank-NDCG@10: -643.037\tvalid's BoltzRank-NDCG@10: -211.23\ttest's BoltzRank-NDCG@10: -199.807\n",
      "min -11.872495871036504 max 0.0 mean -0.14191719014769172 std 0.14162518300797103\n",
      "preds [1.12829131 0.9089386  0.9089386  ... 1.69435768 1.69435768 1.69435768]\n",
      "gain [-0.12542362 -0.32276437 -0.19552762 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[73]\ttrain's BoltzRank-NDCG@10: -643.042\tvalid's BoltzRank-NDCG@10: -211.228\ttest's BoltzRank-NDCG@10: -199.81\n",
      "min -12.196003716378556 max 0.0 mean -0.14191801353249353 std 0.14167714014186034\n",
      "preds [1.14396267 0.92156491 0.92156491 ... 1.71781404 1.71781404 1.71781404]\n",
      "gain [-0.12542132 -0.32276531 -0.19552808 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[74]\ttrain's BoltzRank-NDCG@10: -643.047\tvalid's BoltzRank-NDCG@10: -211.225\ttest's BoltzRank-NDCG@10: -199.813\n",
      "min -12.527858988401936 max 0.0 mean -0.14191885274951924 std 0.14173136812248172\n",
      "preds [1.15963404 0.93419127 0.93419127 ... 1.74126855 1.74126855 1.74126855]\n",
      "gain [-0.12541902 -0.32276625 -0.19552855 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[75]\ttrain's BoltzRank-NDCG@10: -643.051\tvalid's BoltzRank-NDCG@10: -211.223\ttest's BoltzRank-NDCG@10: -199.816\n",
      "min -12.868277599018809 max 0.0 mean -0.14191970809261992 std 0.14178797490895031\n",
      "preds [1.17530543 0.94681769 0.94681769 ... 1.76472122 1.76472122 1.76472122]\n",
      "gain [-0.12541671 -0.32276719 -0.19552901 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[76]\ttrain's BoltzRank-NDCG@10: -643.056\tvalid's BoltzRank-NDCG@10: -211.221\ttest's BoltzRank-NDCG@10: -199.82\n",
      "min -13.217481015865014 max 0.0 mean -0.1419205798638544 std 0.14184707389923723\n",
      "preds [1.19097684 0.95944417 0.95944417 ... 1.78817205 1.78817205 1.78817205]\n",
      "gain [-0.12541441 -0.32276814 -0.19552947 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[77]\ttrain's BoltzRank-NDCG@10: -643.061\tvalid's BoltzRank-NDCG@10: -211.219\ttest's BoltzRank-NDCG@10: -199.823\n",
      "min -13.575696388911425 max 0.0 mean -0.1419214683736428 std 0.1419087841956745\n",
      "preds [1.20664827 0.97207071 0.97207071 ... 1.81162106 1.81162106 1.81162106]\n",
      "gain [-0.12541211 -0.32276908 -0.19552993 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[78]\ttrain's BoltzRank-NDCG@10: -643.066\tvalid's BoltzRank-NDCG@10: -211.216\ttest's BoltzRank-NDCG@10: -199.826\n",
      "min -13.943156687685523 max 0.0 mean -0.14192237394095675 std 0.14197323088412692\n",
      "preds [1.22231972 0.98469731 0.98469731 ... 1.83506825 1.83506825 1.83506825]\n",
      "gain [-0.12540981 -0.32277002 -0.19553039 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[79]\ttrain's BoltzRank-NDCG@10: -643.071\tvalid's BoltzRank-NDCG@10: -211.214\ttest's BoltzRank-NDCG@10: -199.829\n",
      "min -14.320100836609916 max 0.0 mean -0.14192329689349029 std 0.14204054532474208\n",
      "preds [1.23799118 0.99732397 0.99732397 ... 1.85851362 1.85851362 1.85851362]\n",
      "gain [-0.1254075  -0.32277096 -0.19553086 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[80]\ttrain's BoltzRank-NDCG@10: -643.076\tvalid's BoltzRank-NDCG@10: -211.212\ttest's BoltzRank-NDCG@10: -199.833\n",
      "min -14.706773852502145 max 0.0 mean -0.1419242375678373 std 0.14211086545560644\n",
      "preds [1.25366266 1.00995069 1.00995069 ... 1.88195719 1.88195719 1.88195719]\n",
      "gain [-0.1254052  -0.3227719  -0.19553132 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[81]\ttrain's BoltzRank-NDCG@10: -643.081\tvalid's BoltzRank-NDCG@10: -211.21\ttest's BoltzRank-NDCG@10: -199.836\n",
      "min -15.10342699121003 max 0.0 mean -0.14192519630969297 std 0.14218433611108944\n",
      "preds [1.26933416 1.02257746 1.02257746 ... 1.90539894 1.90539894 1.90539894]\n",
      "gain [-0.1254029  -0.32277284 -0.19553178 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[82]\ttrain's BoltzRank-NDCG@10: -643.086\tvalid's BoltzRank-NDCG@10: -211.208\ttest's BoltzRank-NDCG@10: -199.839\n",
      "min -15.510317889374662 max 0.0 mean -0.1419261734740311 std 0.14226110935256323\n",
      "preds [1.28500568 1.0352043  1.0352043  ... 1.9288389  1.9288389  1.9288389 ]\n",
      "gain [-0.1254006  -0.32277378 -0.19553224 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[83]\ttrain's BoltzRank-NDCG@10: -643.092\tvalid's BoltzRank-NDCG@10: -211.205\ttest's BoltzRank-NDCG@10: -199.842\n",
      "min -15.92771071582653 max 0.0 mean -0.1419271694253101 std 0.14234134481484467\n",
      "preds [1.30067721 1.04783119 1.04783119 ... 1.95227707 1.95227707 1.95227707]\n",
      "gain [-0.1253983  -0.32277473 -0.1955327  ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[84]\ttrain's BoltzRank-NDCG@10: -643.097\tvalid's BoltzRank-NDCG@10: -211.203\ttest's BoltzRank-NDCG@10: -199.846\n",
      "min -16.355876322824653 max 0.0 mean -0.14192818453766853 std 0.142425210066853\n",
      "preds [1.31634876 1.06045815 1.06045815 ... 1.97571345 1.97571345 1.97571345]\n",
      "gain [-0.125396   -0.32277567 -0.19553316 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[85]\ttrain's BoltzRank-NDCG@10: -643.103\tvalid's BoltzRank-NDCG@10: -211.201\ttest's BoltzRank-NDCG@10: -199.849\n",
      "min -16.795092402428963 max 0.0 mean -0.14192921919513699 std 0.1425128809880815\n",
      "preds [1.33202033 1.07308516 1.07308516 ... 1.99914804 1.99914804 1.99914804]\n",
      "gain [-0.12539369 -0.32277661 -0.19553363 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[86]\ttrain's BoltzRank-NDCG@10: -643.108\tvalid's BoltzRank-NDCG@10: -211.199\ttest's BoltzRank-NDCG@10: -199.852\n",
      "min -17.245643645137402 max 0.0 mean -0.14193027379184633 std 0.14260454216064172\n",
      "preds [1.34769192 1.08571223 1.08571223 ... 2.02258086 2.02258086 2.02258086]\n",
      "gain [-0.12539139 -0.32277755 -0.19553409 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[87]\ttrain's BoltzRank-NDCG@10: -643.113\tvalid's BoltzRank-NDCG@10: -211.197\ttest's BoltzRank-NDCG@10: -199.856\n",
      "min -17.707821902570686 max 0.0 mean -0.1419313487322448 std 0.14270038727778497\n",
      "preds [1.36336352 1.09833936 1.09833936 ... 2.0460119  2.0460119  2.0460119 ]\n",
      "gain [-0.12538909 -0.32277849 -0.19553455 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[88]\ttrain's BoltzRank-NDCG@10: -643.119\tvalid's BoltzRank-NDCG@10: -211.195\ttest's BoltzRank-NDCG@10: -199.859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min -18.181926354370738 max 0.0 mean -0.1419324444313217 std 0.14280061956936235\n",
      "preds [1.37903515 1.11096655 1.11096655 ... 2.06944118 2.06944118 2.06944118]\n",
      "gain [-0.12538679 -0.32277943 -0.19553501 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[89]\ttrain's BoltzRank-NDCG@10: -643.125\tvalid's BoltzRank-NDCG@10: -211.193\ttest's BoltzRank-NDCG@10: -199.862\n",
      "min -18.668263676177038 max 0.0 mean -0.14193356131482857 std 0.14290545224397064\n",
      "preds [1.39470679 1.1235938  1.1235938  ... 2.09286869 2.09286869 2.09286869]\n",
      "gain [-0.12538449 -0.32278037 -0.19553547 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[90]\ttrain's BoltzRank-NDCG@10: -643.13\tvalid's BoltzRank-NDCG@10: -211.191\ttest's BoltzRank-NDCG@10: -199.866\n",
      "min -19.167148213657057 max 0.0 mean -0.14193469981951504 std 0.1430151089492973\n",
      "preds [1.41037844 1.13622111 1.13622111 ... 2.11629445 2.11629445 2.11629445]\n",
      "gain [-0.12538219 -0.32278132 -0.19553594 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[91]\ttrain's BoltzRank-NDCG@10: -643.136\tvalid's BoltzRank-NDCG@10: -211.189\ttest's BoltzRank-NDCG@10: -199.869\n",
      "min -19.67890216138319 max 0.0 mean -0.14193586039336858 std 0.14312982425082568\n",
      "preds [1.42605012 1.14884848 1.14884848 ... 2.13971846 2.13971846 2.13971846]\n",
      "gain [-0.12537989 -0.32278226 -0.1955364  ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[92]\ttrain's BoltzRank-NDCG@10: -643.142\tvalid's BoltzRank-NDCG@10: -211.187\ttest's BoltzRank-NDCG@10: -199.872\n",
      "min -20.203855740464316 max 0.0 mean -0.14193704349585023 std 0.14324984412785982\n",
      "preds [1.44172181 1.1614759  1.1614759  ... 2.16314071 2.16314071 2.16314071]\n",
      "gain [-0.12537758 -0.3227832  -0.19553686 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[93]\ttrain's BoltzRank-NDCG@10: -643.148\tvalid's BoltzRank-NDCG@10: -211.185\ttest's BoltzRank-NDCG@10: -199.876\n",
      "min -20.74234738521684 max 0.0 mean -0.14193824959814644 std 0.14337542648958942\n",
      "preds [1.45739352 1.17410339 1.17410339 ... 2.18656123 2.18656123 2.18656123]\n",
      "gain [-0.12537528 -0.32278414 -0.19553732 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[94]\ttrain's BoltzRank-NDCG@10: -643.154\tvalid's BoltzRank-NDCG@10: -211.183\ttest's BoltzRank-NDCG@10: -199.879\n",
      "min -21.294723930363595 max 0.0 mean -0.14193947918342079 std 0.1435068417095805\n",
      "preds [1.47306525 1.18673093 1.18673093 ... 2.20998    2.20998    2.20998   ]\n",
      "gain [-0.12537298 -0.32278508 -0.19553778 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[95]\ttrain's BoltzRank-NDCG@10: -643.16\tvalid's BoltzRank-NDCG@10: -211.181\ttest's BoltzRank-NDCG@10: -199.883\n",
      "min -21.861340806138394 max 0.0 mean -0.14194073274707897 std 0.14364437318068476\n",
      "preds [1.488737   1.19935853 1.19935853 ... 2.23339704 2.23339704 2.23339704]\n",
      "gain [-0.12537068 -0.32278602 -0.19553825 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[96]\ttrain's BoltzRank-NDCG@10: -643.166\tvalid's BoltzRank-NDCG@10: -211.179\ttest's BoltzRank-NDCG@10: -199.886\n",
      "min -22.44256223053051 max 0.0 mean -0.14194201079702246 std 0.1437883178880055\n",
      "preds [1.50440876 1.2119862  1.2119862  ... 2.25681235 2.25681235 2.25681235]\n",
      "gain [-0.12536838 -0.32278696 -0.19553871 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[97]\ttrain's BoltzRank-NDCG@10: -643.172\tvalid's BoltzRank-NDCG@10: -211.177\ttest's BoltzRank-NDCG@10: -199.89\n",
      "min -23.038761412482696 max 0.0 mean -0.14194331385392722 std 0.143938987003541\n",
      "preds [1.52008054 1.22461392 1.22461392 ... 2.28022594 2.28022594 2.28022594]\n",
      "gain [-0.12536608 -0.3227879  -0.19553917 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[98]\ttrain's BoltzRank-NDCG@10: -643.178\tvalid's BoltzRank-NDCG@10: -211.175\ttest's BoltzRank-NDCG@10: -199.893\n",
      "min -23.650320755278926 max 0.0 mean -0.14194464245151503 std 0.1440967064999195\n",
      "preds [1.53575234 1.2372417  1.2372417  ... 2.3036378  2.3036378  2.3036378 ]\n",
      "gain [-0.12536378 -0.32278885 -0.19553963 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[99]\ttrain's BoltzRank-NDCG@10: -643.184\tvalid's BoltzRank-NDCG@10: -211.173\ttest's BoltzRank-NDCG@10: -199.896\n",
      "min -24.27763206452672 max 0.0 mean -0.14194599713683573 std 0.1442618177844526\n",
      "preds [1.55142416 1.24986954 1.24986954 ... 2.32704795 2.32704795 2.32704795]\n",
      "gain [-0.12536148 -0.32278979 -0.19554009 ...  0.          0.\n",
      "  0.        ]\n",
      "hess [1. 1. 1. ... 1. 1. 1.]\n",
      "[100]\ttrain's BoltzRank-NDCG@10: -643.19\tvalid's BoltzRank-NDCG@10: -211.171\ttest's BoltzRank-NDCG@10: -199.9\n",
      "training took 11341.875 s\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Model Error')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluation(preds, train_data):\n",
    "    global ds_to_queries\n",
    "    bz = eval_boltzrank(ds_to_queries[len(preds)][0], preds)\n",
    "    return METRIC_NAME, bz, True\n",
    "\n",
    "def compute_grads(preds, train_data): \n",
    "    global ds_to_queries\n",
    "    global train_id\n",
    "    gain, hess = eval_boltzrank_grads(ds_to_queries[train_id][0], preds)\n",
    "    gain = np.asarray(gain)\n",
    "    hess = np.asarray(hess)\n",
    "    print(\"min \" + str(np.min(gain)) + \" max \" + str(np.max(gain)) + \" mean \" + str(np.mean(gain)) + \" std \" + str(np.std(gain)))\n",
    "    print(\"preds \" + str(preds))\n",
    "    print(\"gain \" + str(gain))\n",
    "    print(\"hess \" + str(hess))\n",
    "    return gain, hess\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric':  ['None']\n",
    "}    \n",
    "\n",
    "print(\"training lightgbm...\")\n",
    "start = time.process_time()\n",
    "lgbm_info = {}\n",
    "lgbm_model = lightgbm.train(params, train_lgb, num_boost_round=100,\n",
    "                            feval = evaluation,\n",
    "                            fobj  = compute_grads,\n",
    "                            valid_sets   = [train_lgb, valid_lgb, test_lgb], \n",
    "                            valid_names  = [\"train\", \"valid\", \"test\"],\n",
    "                            evals_result = lgbm_info,\n",
    "                            verbose_eval = 1)\n",
    "print(\"training took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "plt.plot(lgbm_info['train'][METRIC_NAME], label='training')\n",
    "plt.plot(lgbm_info['valid'][METRIC_NAME], label='validation')\n",
    "plt.plot(lgbm_info['test'][METRIC_NAME], label='test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Trees\")\n",
    "plt.ylabel(METRIC_NAME)\n",
    "plt.title(\"Model Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(q, k):\n",
    "    indexes = set(range(0, len(q.perms)))\n",
    "    indexes.remove(k)\n",
    "    result = []\n",
    "    for i in range(len(q.perms[k])):\n",
    "        tmp = set(indexes)\n",
    "        for j in tmp:\n",
    "            if q.perms[k][i] != q.perms[j][i]:\n",
    "                indexes.remove(j)\n",
    "    for w in indexes:\n",
    "        if w < k:\n",
    "            result.append((w, k))\n",
    "        else: \n",
    "            result.append((k,w))\n",
    "    return result\n",
    "\n",
    "def checkRepetitions():\n",
    "    global queries\n",
    "    same = dict()\n",
    "    for q in queries.values():\n",
    "        for i in range(len(q.perms)):\n",
    "            r = check(q, i)\n",
    "            if len(r) != 0:\n",
    "                if not q.qid in same.keys():\n",
    "                    same[q.qid] = set()\n",
    "                for t in r:\n",
    "                    same[q.qid].add(t)\n",
    "\n",
    "    print(str(len(same.keys())) + \"/\" + str(len(queries.keys())) + \" queries have duplicate permutations\")\n",
    "    for q, s in same.items():\n",
    "        print(\"query \" + str(q) + \" has repeated permutations: \" + str(s))\n",
    "        \n",
    "#checkRepetitions()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4dcdedcd6052>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mfreq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "freq = {}\n",
    "for query in queries.values():\n",
    "    for prob in query.probs:\n",
    "        if not prob in freq.keys():\n",
    "            freq[prob] = 0\n",
    "        freq[prob] += 1\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for prob, f in sorted(freq.items()):\n",
    "    x.append(prob)\n",
    "    y.append(f)\n",
    "    \n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "plt.plot(x, y, '.')\n",
    "plt.grid()\n",
    "plt.xlabel(\"probability\")\n",
    "plt.ylabel(\"# rank\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"probabilities of the \" + str(totperms) + \" permutations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}\n",
    "totperms = 0\n",
    "for query in queries.values():\n",
    "    for ndcg in query.ndcgs:\n",
    "        totperms += 1\n",
    "        if not ndcg in freq.keys():\n",
    "            freq[ndcg] = 0\n",
    "        freq[ndcg] += 1\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for ndcg, f in sorted(freq.items()):\n",
    "    x.append(ndcg)\n",
    "    y.append(f)\n",
    "    \n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "plt.plot(x, y, '.')\n",
    "plt.grid()\n",
    "plt.xlabel(\"ndcg@10\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"ndcg@10 frequencies over \" + str(totperms) + \" permutations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
