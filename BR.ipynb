{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# BoltzRank #\n",
    "## Luca Negrini - Mat. 956516 ##\n",
    "### From \"BoltzRank: Learning to Maximize Expected Ranking Gain\" ###\n",
    "#### Maxims M. Volkovs, Richard S. Zemel ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "#### Initialization ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "\n",
    "%load_ext cython\n",
    "\n",
    "# install lightgbm (required only on first run)\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install lightgbm\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_svmlight_file.html\n",
    "from sklearn.datasets import load_svmlight_file \n",
    "\n",
    "# datasets available at: \n",
    "# https://www.microsoft.com/en-us/research/project/mslr/\n",
    "DATASET_FOLDER = \"C:/opt/kiis-training/MSLR-WEB10K/Fold1/\"\n",
    "PERM_FOLDER = DATASET_FOLDER + \"perms/\"\n",
    "METRIC_NAME = 'ndcg@10'#'BoltzRank-NDCG@10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Data loading ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensureFile(path):\n",
    "    if not os.path.exists(path) or not os.path.isfile(path):\n",
    "        raise FileNotFoundError(\"'\" + path + \"': no such file\")        \n",
    "    return path\n",
    "\n",
    "def retrieveFileNames():\n",
    "    folder = DATASET_FOLDER + '/' if DATASET_FOLDER[-1:] != '/' else DATASET_FOLDER\n",
    "    train_file = ensureFile(folder + \"train.txt\")\n",
    "    valid_file = ensureFile(folder + \"vali.txt\")\n",
    "    test_file = ensureFile(folder + \"test.txt\")\n",
    "    return train_file, valid_file, test_file\n",
    "\n",
    "def loadDataset(path):\n",
    "    return load_svmlight_file(path, query_id=True)\n",
    "\n",
    "def loadLightGBM(svmlight_dataset):\n",
    "    query_lens = [sum(1 for _ in group) for key, group in itertools.groupby(svmlight_dataset[2])]\n",
    "    return lightgbm.Dataset(data=svmlight_dataset[0], label=svmlight_dataset[1], group=query_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, qid):\n",
    "        self.qid = qid\n",
    "        self.labels_to_docs = {}\n",
    "    def addlabel(self, label):\n",
    "        if not label in self.labels_to_docs:\n",
    "            self.labels_to_docs[label] = list()\n",
    "    def adddoc(self, label, doc):\n",
    "        self.labels_to_docs[label].append(doc)\n",
    "    def finalize(self, alllabels):\n",
    "        self.labels = np.zeros(len(self.labels_to_docs.keys()), dtype=int)\n",
    "        self.docs = np.empty(len(self.labels_to_docs.keys()), dtype=object)\n",
    "        i = 0\n",
    "        totaldocs = 0\n",
    "        sorteddict = sorted(self.labels_to_docs.items(), reverse = True)\n",
    "        for label, docs in sorteddict:\n",
    "            self.labels[i] = label\n",
    "            self.docs[i] = np.zeros(len(docs), dtype=int)\n",
    "            for j in range(len(docs)):\n",
    "                self.docs[i][j] = docs[j]\n",
    "            i += 1\n",
    "            totaldocs += len(docs)\n",
    "        self.alldocs = np.concatenate(self.docs)\n",
    "        self.flatlabels = np.zeros(totaldocs, dtype=np.double)\n",
    "        i = 0\n",
    "        for label, docs in sorteddict:\n",
    "            for j in range(len(docs)):\n",
    "                self.flatlabels[i] = label\n",
    "                i += 1       \n",
    "        k = min(10, len(self.alldocs))\n",
    "        self.idealdcg = dcg_k(self.alldocs, alllabels, k) \n",
    "        del self.labels_to_docs\n",
    "    def setperms(self, perms):\n",
    "        self.perms = perms\n",
    "    def setndcgs(self, ndcgs):\n",
    "        self.ndcgs = ndcgs\n",
    "    def __repr__(self):  \n",
    "        return str(self)\n",
    "    def __str__(self):\n",
    "        res = \"Query \" + str(self.qid) + \"[\"\n",
    "        res += \"\\nideal dcg: \" + str(self.idealdcg)\n",
    "        for i in range(len(self.labels)):\n",
    "            res += \"\\n\" + str(self.labels[i]) + \" -> \" + str(self.docs[i])\n",
    "        res += \"]\"\n",
    "        if hasattr(self, 'perms'):\n",
    "            for i in range(len(self.perms)):\n",
    "                res += \"\\n[\" + str(self.perms[i]) + \"] -> dcg: \" + str(self.ndcgs[i])\n",
    "        else:\n",
    "            res += \"\\nNo permutations computed yet\"\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "#  dataset: svmlight_dataset \n",
    "#      the datset to process\n",
    "# returned values:\n",
    "#  query_to_labels_to_documents: dict(int -> dict(float -> list(int)))\n",
    "#      a map containing, for each query in the dataset, the documents (row index in the dataset) provided \n",
    "#      in the input dataset grouped by label\n",
    "#  doc_to_query: dict(document -> query)\n",
    "#      a mapping between document (row index in the dataset) and the relative query\n",
    "def mapQueryToDocuments(dataset):\n",
    "    queries = {}\n",
    "    alllabels = np.negative(np.ones(len(dataset[2]), dtype=np.double))\n",
    "    for i in range(0, len(dataset[2])):\n",
    "        if not dataset[2][i] in queries:\n",
    "            queries[dataset[2][i]] = Query(dataset[2][i])\n",
    "        query = queries[dataset[2][i]]\n",
    "        query.addlabel(dataset[1][i])\n",
    "        query.adddoc(dataset[1][i], i)\n",
    "        alllabels[i] = dataset[1][i]\n",
    "        \n",
    "    for q in queries.values():\n",
    "        q.finalize(alllabels)\n",
    "    \n",
    "    return queries, alllabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Rank sample set generation ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "from libc.math cimport exp\n",
    "from cython.parallel import prange\n",
    "from cython import boundscheck, wraparound, cdivision\n",
    "from libc.math cimport log2\n",
    "from math import factorial\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc\n",
    "from libc.stdlib cimport free\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double* E(int[:] R, double[:] S) nogil:\n",
    "    cdef int k, j, m = len(R)\n",
    "    cdef double* energy = <double *> malloc(m*sizeof(double))\n",
    "    cdef double res_w_S, factor \n",
    "    if m == 1 or m == 0:\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = 0\n",
    "    else:\n",
    "        factor = 4.0 / (m * ((m - 1)**2))\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            res_w_S = 0.0\n",
    "            for k in range(len(R)):\n",
    "                if k < j: \n",
    "                    res_w_S = res_w_S + (j - k) * (S[R[j]] - S[R[k]])\n",
    "                elif k > j: \n",
    "                    res_w_S = res_w_S + (k - j) * (S[R[k]] - S[R[j]])\n",
    "            energy[j] = factor * res_w_S\n",
    "    return energy\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void P(int[:,:] Rq, double[:] S, double[:,:] probs, double[:] accumulator) nogil:\n",
    "    cdef int rankid, pos, doc\n",
    "    cdef double* en\n",
    "    for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "        en = E(Rq[rankid], S)\n",
    "        for pos in range(len(Rq[rankid])):\n",
    "            doc = Rq[rankid][pos]\n",
    "            probs[doc][rankid] = exp(-en[pos]) # e^{-E}\n",
    "            accumulator[doc] = accumulator[doc] + probs[doc][rankid] # sum(e^{-E})\n",
    "        free(en)\n",
    "    for pos in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][pos]\n",
    "        # e^{-E} / sum(e^{-E})\n",
    "        probs[doc][rankid] = probs[doc][rankid] / accumulator[doc]\n",
    "        \n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                              NDCG EVALUATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cpdef double dcg_k(int[:] rank, double[:] scores, int k) nogil:\n",
    "    cdef double result = 0\n",
    "    cdef int i\n",
    "    for i in prange(k, schedule='static', num_threads=8):\n",
    "        result += (2**scores[rank[i]] - 1) / (log2(i + 2)) # should be i+1, but with numbering starting from 1 instead of 0\n",
    "    return result\n",
    "\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double ndcg_k(int[:] rank, double[:] scores, int k, double ideal) nogil:\n",
    "    if ideal == 0:\n",
    "        return 1.0\n",
    "    return dcg_k(rank, scores, k) / ideal\n",
    "\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "#                                          PERMUTATIONS GENERATION\n",
    "###############################################################################################################\n",
    "###############################################################################################################\n",
    "\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "RANK_SAMPLE_SET_DISTRIBUTIONS = [\n",
    "                                int(.30 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->0\n",
    "                                int(.22 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->1\n",
    "                                int(.18 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->2\n",
    "                                int(.12 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 4->3\n",
    "                                int(.10 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->0\n",
    "                                int(.06 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->1\n",
    "                                int(.02 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 3->2\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->0\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS), # 2->1\n",
    "                                int(.0 * RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS)  # 1->0\n",
    "                                ]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef bint contained(int[:,:] container, int[:] array) nogil:\n",
    "    cdef bint match\n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    for i in prange(len(container), schedule='static', num_threads=8):\n",
    "        if container[i][0] == -1 or len(container[i]) != len(array):\n",
    "            continue\n",
    "        else:\n",
    "            match = True\n",
    "            for j in range(len(container[i])):\n",
    "                if container[i][j] != array[j]:\n",
    "                    match = False\n",
    "                    break\n",
    "            if match:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void setrow(int[:,:] container, int pos, int[:] array) nogil:\n",
    "    cdef int i\n",
    "    for i in prange(len(container[pos]), schedule='static', num_threads=8):\n",
    "        container[pos][i] = array[i]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int[:,:] allPerms(int[:] source, long long fact):\n",
    "    cdef int i = 0\n",
    "    cdef int k\n",
    "    perm = itertools.permutations(source)\n",
    "    cdef int[:,:] result = np.zeros((fact, len(source)), dtype=int)\n",
    "    for p in perm:\n",
    "        for k in range(len(p)):\n",
    "            result[i][k] = p[k]\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "#source: label -> docid*, i: int, j: int, count: int, perms_with_prob: tuple<int> -> float\n",
    "#return: number of not computed permutations\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def perform_permutation(query, int i, int j, int count, int[:,:] perms, int start):\n",
    "    if not i in query.labels or not j in query.labels:\n",
    "        # no swapping possible\n",
    "        return count, start\n",
    "    # find the indexes of the desired labels\n",
    "    i = [k for k in range(len(query.labels)) if query.labels[k] == i][0]\n",
    "    j = [k for k in range(len(query.labels)) if query.labels[k] == j][0]\n",
    "    cdef int c = 0\n",
    "    cdef int _min = min(len(query.docs[i]), len(query.docs[j]))\n",
    "    cdef int amount = max(1, int(_min * .5))\n",
    "    limit = factorial(_min) / (factorial(amount) * factorial(_min - amount))\n",
    "    cdef int k\n",
    "    cdef int d\n",
    "    for k in range(count):\n",
    "        perm = query.docs.copy()\n",
    "        first = random.sample(range(len(query.docs[i])), k=amount)\n",
    "        second = random.sample(range(len(query.docs[j])), k=amount)\n",
    "        for d in range(len(first)):\n",
    "            perm[i][first[d]], perm[j][second[d]] = query.docs[j][second[d]], query.docs[i][first[d]]\n",
    "        p = np.concatenate(perm)\n",
    "        if not contained(perms, p):\n",
    "            setrow(perms, start + c, p)\n",
    "            c += 1\n",
    "            if c == limit:\n",
    "                return count - c, start + c\n",
    "        else:\n",
    "            k -= 1\n",
    "    return 0, start + c\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def process_query(query, alllabels, probs, accumulator):\n",
    "    cdef int carry = 0\n",
    "    fact = factorial(len(query.alldocs))\n",
    "    cdef perms\n",
    "    cdef int last = 0\n",
    "    if fact <= RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS:\n",
    "        # evaluate all possible permutations, each one representing a different ranking\n",
    "        perms = allPerms(query.alldocs, fact)\n",
    "    else:\n",
    "        perms = np.negative(np.ones((RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS, len(query.alldocs)), dtype=int))\n",
    "        # switch the labels of the documents, then sort the documents by label to obtain a ranking\n",
    "        carry, last = perform_permutation(query, 4, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[0], perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[1] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[2] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 4, 3, RANK_SAMPLE_SET_DISTRIBUTIONS[3] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[4] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[5] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 3, 2, RANK_SAMPLE_SET_DISTRIBUTIONS[6] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[7] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 2, 1, RANK_SAMPLE_SET_DISTRIBUTIONS[8] + carry, perms, last)\n",
    "        carry, last = perform_permutation(query, 1, 0, RANK_SAMPLE_SET_DISTRIBUTIONS[9] + carry, perms, last)\n",
    "        if carry != 0:\n",
    "            if not query.alldocs in perms:\n",
    "                perms[last] = query.alldocs\n",
    "        perms = perms[perms.max(axis=1)>=0]\n",
    "    query.setperms(perms)  \n",
    "    P(perms, alllabels, probs, accumulator)\n",
    "    cdef double[:] ndcgs = np.zeros(len(perms))\n",
    "    cdef int k = min(10, len(perms[0]))\n",
    "    for i in range(len(perms)):\n",
    "        ndcgs[i] = ndcg_k(perms[i], alllabels, k, query.idealdcg)\n",
    "    query.setndcgs(ndcgs)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/train.txt\n",
      "validation file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/vali.txt\n",
      "test file: C:/opt/kiis-training/MSLR-WEB10K/Fold1/test.txt\n",
      "loading datasets... \n",
      "train dataset loading took 116.5625 s\n",
      "validation dataset loading took 39.75 s\n",
      "test dataset loading took 36.640625 s\n",
      "converting datasets to LightGBM format... \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "train_file, valid_file, test_file = retrieveFileNames()\n",
    "\n",
    "print(\"training file: \" + train_file)\n",
    "print(\"validation file: \" + valid_file)\n",
    "print(\"test file: \" + test_file)\n",
    "    \n",
    "print(\"loading datasets... \")\n",
    "import time\n",
    "start = time.process_time()\n",
    "train_dataset = loadDataset(train_file)\n",
    "print(\"train dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "valid_dataset = loadDataset(valid_file)\n",
    "print(\"validation dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "start = time.process_time()\n",
    "test_dataset = loadDataset(test_file)\n",
    "print(\"test dataset loading took \" + str(time.process_time() - start) + \" s\")\n",
    "\n",
    "import itertools\n",
    "print(\"converting datasets to LightGBM format... \")\n",
    "train_lgb = loadLightGBM(train_dataset)\n",
    "valid_lgb = loadLightGBM(valid_dataset)\n",
    "test_lgb = loadLightGBM(test_dataset)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating query-documents mappings...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def file_len(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1\n",
    "\n",
    "print(\"creating query-documents mappings...\")\n",
    "train_id = file_len(train_file)\n",
    "vali_id = file_len(valid_file)\n",
    "test_id = file_len(test_file)\n",
    "ds_to_queries = {}\n",
    "ds_to_queries[train_id] = mapQueryToDocuments(train_dataset)\n",
    "ds_to_queries[vali_id] = mapQueryToDocuments(valid_dataset)\n",
    "ds_to_queries[test_id] = mapQueryToDocuments(test_dataset)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating sample sets...\n",
      "sample set creation took 191.984375 s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"creating sample sets...\")\n",
    "start = time.process_time()\n",
    "\n",
    "probs_with_labels = {}\n",
    "RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS = 100\n",
    "for ds_id, queries in ds_to_queries.items():\n",
    "    probs_with_labels[ds_id] = np.zeros((len(queries[1]), RANK_SAMPLE_SET_MAX_QUERY_PERMUTATIONS))\n",
    "    accumulator = np.zeros(len(queries[1]))\n",
    "    for q in queries[0].values():\n",
    "        process_query(q, queries[1], probs_with_labels[ds_id], accumulator)    \n",
    "    del accumulator\n",
    "    \n",
    "print(\"sample set creation took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "#### BoltzRank logic ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython \n",
    "from libc.math cimport exp\n",
    "from cython.parallel import prange\n",
    "from cython import boundscheck, wraparound, cdivision\n",
    "from libc.math cimport log\n",
    "from math import factorial\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "from libc.stdio cimport printf\n",
    "from libc.stdlib cimport malloc\n",
    "from libc.stdlib cimport free\n",
    "\n",
    "# Energy function.\n",
    "# params: \n",
    "#  R      the ranking to evaluate. Element i contains the id of the document in position i\n",
    "#  S      the scoring vector. Element i contains the score of the document with id i\n",
    "# returns:\n",
    "#  a c matrix of size (m,2). Row i contains (energy, energy') w.r.t. document i\n",
    "#  NB: call free on the returned matrix.\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef double** E(int[:] R, double[:] S) nogil:\n",
    "    cdef int k, j, m = len(R)\n",
    "    cdef double** energy = <double **> malloc(m*sizeof(double*))\n",
    "    cdef double res, res_w_S, factor\n",
    "    if m == 1 or m == 0:\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = <double *> malloc(2*sizeof(double))\n",
    "            energy[j][0] = 0\n",
    "            energy[j][1] = 0\n",
    "    else:\n",
    "        factor = 4.0 / (m * ((m - 1)**2))\n",
    "        for j in prange(len(R), schedule='static', num_threads=8):\n",
    "            energy[j] = <double *> malloc(2*sizeof(double))\n",
    "            res = 0.0\n",
    "            res_w_S = 0.0\n",
    "            for k in range(len(R)):\n",
    "                if k < j: \n",
    "                    res = res + (j - k)\n",
    "                    res_w_S = res_w_S + (j - k) * (S[R[j]] - S[R[k]])\n",
    "                elif k > j: \n",
    "                    res = res + (k - j)\n",
    "                    res_w_S = res_w_S + (k - j) * (S[R[k]] - S[R[j]])\n",
    "            energy[j][0] = factor * res_w_S\n",
    "            energy[j][1] = factor * res\n",
    "    return energy\n",
    "\n",
    "# Probability function.\n",
    "# params: \n",
    "#  Rq    the rank sample set. Element i contains the i-th ranking, that is, an array of document ids\n",
    "#  S     the scoring vector. Element i contains the score of the document with id i\n",
    "#  probs a c matrix of size (len(S),len(Rq),3). Each row i contains the result of the computation w.r.t. document i. Each row contains a \n",
    "#        matrix (len(Rq),3) containing, for each ranking, a tuple (probability, probability', probability'')\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void P(int[:,:] Rq, double[:] S, double*** probs, double** accumulator) nogil:\n",
    "    cdef int rankid, pos, doc\n",
    "    cdef double** en\n",
    "    \n",
    "    for pos in range(len(Rq[0])):\n",
    "        doc = Rq[0][pos]\n",
    "        probs[doc] = <double **> malloc(len(Rq)*sizeof(double*))\n",
    "        accumulator[doc] = <double *> malloc(2*sizeof(double*))\n",
    "        for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "            probs[doc][rankid] = <double *> malloc(3*sizeof(double))\n",
    "    \n",
    "    for rankid in prange(len(Rq), schedule='static', num_threads=8):\n",
    "        en = E(Rq[rankid], S)\n",
    "        for pos in range(len(Rq[rankid])):\n",
    "            doc = Rq[rankid][pos]\n",
    "            if isnan(en[pos][0]):\n",
    "                printf(\"ENERGY 0 NAN for %d rank %d: %f %f\\n\", pos, rankid, en[pos][0], en[pos][1])\n",
    "                with gil:\n",
    "                    raise TypeError(\"foo\")\n",
    "            if isnan(en[pos][1]):\n",
    "                printf(\"ENERGY 1 NAN for %d rank %d: %f %f\\n\", pos, rankid, en[pos][0], en[pos][1])\n",
    "                with gil:\n",
    "                    raise TypeError(\"foo\")\n",
    "            probs[doc][rankid][0] = exp(-en[pos][0]) # e^{-E}\n",
    "            probs[doc][rankid][1] = 0\n",
    "            probs[doc][rankid][2] = en[pos][1] # E'\n",
    "            if isnan(probs[doc][rankid][0]):\n",
    "                printf(\"e^{-E} NAN for %d rank %d\\n\", doc, rankid)\n",
    "                with gil:\n",
    "                    raise TypeError(\"foo\")\n",
    "            if isnan(probs[doc][rankid][2]):\n",
    "                printf(\"E'NAN for %d rank %d\\n\", doc, rankid)\n",
    "                with gil:\n",
    "                    raise TypeError(\"foo\")\n",
    "            accumulator[doc][0] = accumulator[doc][0] + probs[doc][rankid][0] # sum(e^{-E})\n",
    "            accumulator[doc][1] = accumulator[doc][1] + (-en[pos][1] * probs[doc][rankid][0]) # sum(-E' * e^{-E})\n",
    "            accumulator[doc][2] = accumulator[doc][2] + ((en[pos][1]**2) * probs[doc][rankid][0]) # sum(E'^2 * e^{-E})\n",
    "            free(en[pos])\n",
    "        free(en)\n",
    "\n",
    "    for pos in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][pos]\n",
    "        # e^{-E} / sum(e^{-E})\n",
    "        probs[doc][rankid][0] = probs[doc][rankid][0] / accumulator[doc][0] \n",
    "        if isnan(probs[doc][rankid][0]):\n",
    "            printf(\"P NAN for %d rank %d: %f %f\\n\", doc, rankid, probs[doc][rankid][0], accumulator[doc][0])\n",
    "            with gil:\n",
    "                raise TypeError(\"foo\")\n",
    "        \n",
    "        # -P * (E' + (sum(-E' * e^{-E}) / sum(e^{-E})))\n",
    "        probs[doc][rankid][1] = -probs[doc][rankid][0] * (probs[doc][rankid][2] + (accumulator[doc][1] / accumulator[doc][0]))\n",
    "        if isnan(probs[doc][rankid][0]):\n",
    "            printf(\"P' NAN for %d rank %d: %f %f %f %f\\n\", doc, rankid, probs[doc][rankid][0], probs[doc][rankid][2], accumulator[doc][0], accumulator[doc][1])\n",
    "            with gil:\n",
    "                raise TypeError(\"foo\")\n",
    "                \n",
    "        # -P' * (E' + (sum(-E' * e^{-E}) / sum(e^{-E}))) - P * (1 + (sum(E'^2 * e^{-E}) / sum(-E' * e^{-E})) - (sum(-E' * e^{-E})^2 / sum(e^{-E})^2))\n",
    "        probs[doc][rankid][2] = (-probs[doc][rankid][1] * (probs[doc][rankid][2] + (accumulator[doc][1] / accumulator[doc][0]))) \n",
    "        probs[doc][rankid][2] = probs[doc][rankid][2] - (probs[doc][rankid][0] * (1 + ((accumulator[doc][2] / accumulator[doc][0]) - (accumulator[doc][1]**2 / accumulator[doc][0]**2))))\n",
    "        if isnan(probs[doc][rankid][0]):\n",
    "            printf(\"P'' NAN for %d rank %d: %f %f %f %f\\n\", doc, rankid, probs[doc][rankid][0], probs[doc][rankid][1], probs[doc][rankid][2], accumulator[doc][0], accumulator[doc][1], accumulator[doc][2])\n",
    "            with gil:\n",
    "                raise TypeError(\"foo\")\n",
    "        \n",
    "        free(accumulator[doc])\n",
    "        \n",
    "# Gain function.\n",
    "# params: \n",
    "#  Rq                the rank sample set. Element i contains the i-th ranking, that is, an array of document ids\n",
    "#  probs             a c matrix of size (len(S),len(Rq),3). Each row i contains the result of the computation w.r.t. document i. Each row contains a \n",
    "#                    matrix (len(Rq),3) containing, for each ranking, a tuple (probability, probability', probability'')\n",
    "#  probs_with_labels a c matrix of size (len(S),len(Rq)). Each row i contains the result of the computation w.r.t. document i. Each row contains an \n",
    "#                    array (len(Rq)) containing, for each ranking, its probability w.r.t. the target labeling\n",
    "#  gains             a c matrix of size (len(S),3) containing, for each document, the evaluated gain with its two derivatives. \n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef void monte_carlo_gain(int[:,:] Rq, double*** probs, double[:] ndcgs, double** gains) nogil:\n",
    "    cdef int i, doc, j\n",
    "    for i in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][i]\n",
    "        gains[doc] = <double*> malloc(3*sizeof(double))\n",
    "        for j in range(len(Rq)):\n",
    "            gains[doc][0] = gains[doc][0] + probs[doc][j][0] * ndcgs[j]\n",
    "            gains[doc][1] = gains[doc][1] + probs[doc][j][1] * ndcgs[j]\n",
    "            gains[doc][2] = gains[doc][2] + probs[doc][j][2] * ndcgs[j]\n",
    "        \n",
    "# Cross entropy function.\n",
    "# params: \n",
    "#  Rq                the rank sample set. Element i contains the i-th ranking, that is, an array of document ids\n",
    "#  probs             a c matrix of size (len(S),len(Rq),3). Each row i contains the result of the computation w.r.t. document i. Each row contains a \n",
    "#                    matrix (len(Rq),3) containing, for each ranking, a tuple (probability, probability', probability'')\n",
    "#  probs_with_labels a c matrix of size (len(S),len(Rq)). Each row i contains the result of the computation w.r.t. document i. Each row contains an \n",
    "#                    array (len(Rq)) containing, for each ranking, its probability w.r.t. the target labeling\n",
    "#  entropies         a c matrix of size (len(S),3) containing, for each document, the evaluated cross entropy with its two derivatives. \n",
    "#                    NB the entropy's sign has not yet being flipped \n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "@cdivision(True)\n",
    "cdef void cross_entropy(int[:,:] Rq, double*** probs, double[:,:] probs_with_labels, double** entropies) nogil:\n",
    "    cdef int i, doc, j\n",
    "    for i in prange(len(Rq[0]), schedule='static', num_threads=8):\n",
    "        doc = Rq[0][i]\n",
    "        entropies[doc] = <double*> malloc(3*sizeof(double))\n",
    "        for j in range(len(Rq)):\n",
    "            # P(L)log(P(S))\n",
    "            entropies[doc][0] = entropies[doc][0] + probs_with_labels[doc][j] * log(probs[doc][j][0])\n",
    "            # P(L)(P'(S)/P(S))\n",
    "            entropies[doc][1] = entropies[doc][1] + (probs_with_labels[doc][j] * probs[doc][j][1] / probs[doc][j][0])\n",
    "            # P(L)(P''(S)-P'(S)^2)/P(S)\n",
    "            entropies[doc][2] = entropies[doc][2] + (probs_with_labels[doc][j] * ((probs[doc][j][2] - probs[doc][j][1]**2) / probs[doc][j][0]))\n",
    "            free(probs[doc][j])\n",
    "        free(probs[doc])\n",
    "    \n",
    "from libc.math cimport isnan\n",
    "\n",
    "# Boltzrank grads and hess evaluation function.\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def eval_boltzrank_grads(queries, S, probs_with_labels): \n",
    "    cdef double lam = .9\n",
    "    cdef double[:] gain = np.ones_like(S)\n",
    "    cdef double[:] hess = np.ones_like(S) \n",
    "    \n",
    "    cdef int i\n",
    "    cdef double*** probs = <double***> malloc(len(S)*sizeof(double**))\n",
    "    cdef double** accumulator = <double**> malloc(len(S)*sizeof(double*))\n",
    "    cdef double** gains = <double**> malloc(len(S)*sizeof(double*))\n",
    "    cdef double** entropies = <double**> malloc(len(S)*sizeof(double*)) \n",
    "    for q in queries.values():\n",
    "        P(q.perms, S, probs, accumulator)\n",
    "        monte_carlo_gain(q.perms, probs, q.ndcgs, gains) \n",
    "        cross_entropy(q.perms, probs, probs_with_labels, entropies)\n",
    "    for i in range(len(gain)):\n",
    "        gain[i] = (lam * gains[i][1]) - ((1-lam) * -entropies[i][1])\n",
    "        hess[i] = (lam * gains[i][2]) - ((1-lam) * -entropies[i][2])\n",
    "        free(gains[i])\n",
    "        free(entropies[i])\n",
    "    free(gains)\n",
    "    free(entropies)\n",
    "    free(probs)\n",
    "    free(accumulator)\n",
    "    return gain, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(preds, train_data):\n",
    "    global ds_to_queries\n",
    "    #bz = eval_boltzrank(ds_to_queries[len(preds)][0], preds)\n",
    "    labels = train_data.get_label()\n",
    "    avg_mse = 0.5 * np.mean( (labels-preds)**2 )\n",
    "    print(\"MSE eval: \" + str(avg_mse))\n",
    "    return 'MSE', avg_mse, False\n",
    "\n",
    "def compute_grads(preds, train_data): \n",
    "    global ds_to_queries\n",
    "    global train_id\n",
    "    global probs_with_labels\n",
    "    gain, hess = eval_boltzrank_grads(ds_to_queries[train_id][0], preds, probs_with_labels[train_id])\n",
    "    gain = np.asarray(gain)\n",
    "    hess = np.asarray(hess)\n",
    "    print(\"preds \" + str(preds))\n",
    "    print(\"gain \" + str(gain))\n",
    "    print(\"GAIN: min \" + str(np.min(gain)) + \" max \" + str(np.max(gain)) + \" mean \" + str(np.mean(gain)) + \" std \" + str(np.std(gain)))\n",
    "    print(\"hess \" + str(hess))\n",
    "    print(\"HESS: min \" + str(np.min(hess)) + \" max \" + str(np.max(hess)) + \" mean \" + str(np.mean(hess)) + \" std \" + str(np.std(hess)))\n",
    "    return gain, hess\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 16,\n",
    "    'min_data_in_leaf': 5,\n",
    "    'metric': ['ndcg'],# ['None']\n",
    "    'ndcg_eval_at': 10\n",
    "}    \n",
    "\n",
    "print(\"training lightgbm...\")\n",
    "start = time.process_time()\n",
    "lgbm_info = {}\n",
    "lgbm_model = lightgbm.train(params, train_lgb, num_boost_round=100,\n",
    "                            #feval = evaluation,\n",
    "                            fobj  = compute_grads,\n",
    "                            valid_sets   = [train_lgb, valid_lgb, test_lgb], \n",
    "                            valid_names  = [\"train\", \"valid\", \"test\"],\n",
    "                            evals_result = lgbm_info,\n",
    "                            verbose_eval = 1)\n",
    "print(\"training took \" + str(time.process_time() - start) + \" s\")\n",
    "print(\"done\")\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "plt.plot(lgbm_info['train'][METRIC_NAME], label='training')\n",
    "plt.plot(lgbm_info['valid'][METRIC_NAME], label='validation')\n",
    "plt.plot(lgbm_info['test'][METRIC_NAME], label='test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"# Trees\")\n",
    "plt.ylabel(METRIC_NAME)\n",
    "plt.title(\"Model Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(q, k):\n",
    "    indexes = set(range(0, len(q.perms)))\n",
    "    indexes.remove(k)\n",
    "    result = []\n",
    "    for i in range(len(q.perms[k])):\n",
    "        tmp = set(indexes)\n",
    "        for j in tmp:\n",
    "            if q.perms[k][i] != q.perms[j][i]:\n",
    "                indexes.remove(j)\n",
    "    for w in indexes:\n",
    "        if w < k:\n",
    "            result.append((w, k))\n",
    "        else: \n",
    "            result.append((k,w))\n",
    "    return result\n",
    "\n",
    "def checkRepetitions():\n",
    "    global queries\n",
    "    same = dict()\n",
    "    for q in queries.values():\n",
    "        for i in range(len(q.perms)):\n",
    "            r = check(q, i)\n",
    "            if len(r) != 0:\n",
    "                if not q.qid in same.keys():\n",
    "                    same[q.qid] = set()\n",
    "                for t in r:\n",
    "                    same[q.qid].add(t)\n",
    "\n",
    "    print(str(len(same.keys())) + \"/\" + str(len(queries.keys())) + \" queries have duplicate permutations\")\n",
    "    for q, s in same.items():\n",
    "        print(\"query \" + str(q) + \" has repeated permutations: \" + str(s))\n",
    "        \n",
    "#checkRepetitions()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}\n",
    "for query in queries.values():\n",
    "    for prob in query.probs:\n",
    "        if not prob in freq.keys():\n",
    "            freq[prob] = 0\n",
    "        freq[prob] += 1\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for prob, f in sorted(freq.items()):\n",
    "    x.append(prob)\n",
    "    y.append(f)\n",
    "    \n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "plt.plot(x, y, '.')\n",
    "plt.grid()\n",
    "plt.xlabel(\"probability\")\n",
    "plt.ylabel(\"# rank\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"probabilities of the \" + str(totperms) + \" permutations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}\n",
    "totperms = 0\n",
    "for query in queries.values():\n",
    "    for ndcg in query.ndcgs:\n",
    "        totperms += 1\n",
    "        if not ndcg in freq.keys():\n",
    "            freq[ndcg] = 0\n",
    "        freq[ndcg] += 1\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for ndcg, f in sorted(freq.items()):\n",
    "    x.append(ndcg)\n",
    "    y.append(f)\n",
    "    \n",
    "plt.figure(figsize=(9,6), tight_layout=True)\n",
    "plt.plot(x, y, '.')\n",
    "plt.grid()\n",
    "plt.xlabel(\"ndcg@10\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"ndcg@10 frequencies over \" + str(totperms) + \" permutations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
